{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46e3528-f435-4c07-92e9-b74c5f062df9",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6528f9ad-fbc6-4822-8965-d5e70ce3156b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 14:28:48.760606: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-16 14:28:48.775498: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-16 14:28:48.807720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-16 14:28:48.860810: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-16 14:28:48.860899: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-16 14:28:48.896690: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-16 14:28:51.630005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from helpers import parse_variables, get_risk_level, hi_gauss_blob_risk_fun, blob_risk_fun, NW_risk_fun, square_risk_fun, map_to_color\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import importlib.util\n",
    "from k_means_constrained import KMeansConstrained\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "\n",
    "from helpers import parse_variables, get_risk_level, map_to_color, simulate_quant_trait\n",
    "from models import ols_regression, manhattan_linear, gc\n",
    "from deep_learning_models import abyss, deep_abyss\n",
    "\n",
    "from scipy.stats import t\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Input, Model, layers, regularizers\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487575fc-b220-49b6-9ef8-d1b027620a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = parse_variables('geno_simulation.txt')\n",
    "G = int(dict['G'])\n",
    "L = int(dict['L'])\n",
    "c = int(dict['c'])\n",
    "k = int(dict['k'])\n",
    "M = float(dict['M'])\n",
    "\n",
    "# Thresholds\n",
    "very_rare_threshold_L = float(dict['very_rare_threshold_L'])\n",
    "very_rare_threshold_H = float(dict['very_rare_threshold_H'])\n",
    "\n",
    "rare_threshold_L = float(dict['rare_threshold_L'])\n",
    "rare_threshold_H = float(dict['rare_threshold_H'])\n",
    "\n",
    "common_threshold_L = float(dict['common_threshold_L'])\n",
    "common_threshold_H = float(dict['common_threshold_H'])\n",
    "\n",
    "number_of_snps = (G*L)/2 # one loci per chromosome\n",
    "number_of_individuals = c*k*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80e4e39-c78b-4e06-8948-1665faef4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_veryrare_genotype_AF_{very_rare_threshold_L}_{very_rare_threshold_H}.pkl\")\n",
    "rare = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_rare_genotype_AF_{rare_threshold_L}_{rare_threshold_H}.pkl\")\n",
    "common = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_common_genotype_AF_{common_threshold_L}_{common_threshold_H}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd20320-65c5-4ba5-9770-8d6f9442e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare = very_rare.rename(columns=lambda x: 'VR' + x)/2\n",
    "rare = rare.rename(columns=lambda x: 'R' + x)/2\n",
    "common = common.rename(columns=lambda x: 'C' + x)/2\n",
    "complete = pd.concat([common, rare, very_rare], axis=1)\n",
    "complete = ((complete*2)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb470fa-be9d-49d5-b0cd-facb535506a5",
   "metadata": {},
   "source": [
    "# Run Abyss on LD block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c1ef5cc-3417-4578-8e4f-823624c60869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maf_prediction(bottle_in, geno_out, epoch, patience):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(bottle_in, geno_out, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Regularization parameter\n",
    "    l2_regularizer = 0.001\n",
    "    \n",
    "    # Original autoencoder model with L2 regularization\n",
    "    decoder = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(150, activation='elu', input_shape=(bottle_in.shape[1],), kernel_regularizer=regularizers.l2(l2_regularizer)),  # First hidden layer with L2 regularization\n",
    "        layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('elu'),\n",
    "        tf.keras.layers.Dense(geno_out.shape[1], activation='linear', kernel_regularizer=regularizers.l2(l2_regularizer))  # Output layer\n",
    "    ])\n",
    "    \n",
    "    # Compile the original model with L2 regularization\n",
    "    decoder.compile(optimizer='adam',\n",
    "                        loss='mean_squared_error',\n",
    "                        metrics=['mean_absolute_error'])\n",
    "    \n",
    "    # Define Early Stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    \n",
    "    # Fit the original model with Early Stopping\n",
    "    history = decoder.fit(X_train, y_train, epochs=epoch, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    return decoder, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decfe955-a11e-4c6f-a52c-a40a5c289963",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/LD_blocks_estimated_mafs\"\n",
    "os.system(f\"rm -rf {path_output}\")\n",
    "os.makedirs(path_output, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7a7768-0bda-4cc3-abc4-8684af2e1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle_path = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/phenotype/abyss_bottleneck\"\n",
    "bottle_file = [f for f in os.listdir(bottle_path) if f.split('_')[1] == 'bottleneck'][0]\n",
    "bottle = pd.read_pickle(f\"{bottle_path}/{bottle_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "026d8722-20ab-4942-8df2-083c2d20a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = bottle['cluster']\n",
    "bottle.drop(\"cluster\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3362dc25-da78-4585-8b16-fe49f64ddc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_one_hot_genotype = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/LD_blocks_one_hot/\"\n",
    "path_lds = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/LD_blocks\"\n",
    "ld_files = os.listdir(path_lds)\n",
    "\n",
    "\n",
    "epoch = 200\n",
    "patience = 15\n",
    "p2s = []\n",
    "twopqs = []\n",
    "q2s = []\n",
    "for ld_file in ld_files:\n",
    "    db_minor = pd.read_pickle(f\"{path_one_hot_genotype}{ld_file.split('.pkl')[0]}_db_minor.pkl\")\n",
    "    db_het = pd.read_pickle(f\"{path_one_hot_genotype}{ld_file.split('.pkl')[0]}_db_het.pkl\")\n",
    "    db_major = pd.read_pickle(f\"{path_one_hot_genotype}{ld_file.split('.pkl')[0]}_db_major.pkl\")\n",
    "    \n",
    "    decoder, history = maf_prediction(bottle, db_major, epoch, patience)\n",
    "    p2 = decoder(tf.convert_to_tensor(bottle, dtype=tf.float32))\n",
    "    p2 = pd.DataFrame(data=p2, columns = db_major.columns)\n",
    "\n",
    "    p2.index = db_major.index\n",
    "    p2s.append(p2)\n",
    "\n",
    "    decoder, history = maf_prediction(bottle, db_het, epoch, patience)\n",
    "    twopq = decoder(tf.convert_to_tensor(bottle, dtype=tf.float32))\n",
    "    twopq = pd.DataFrame(data=twopq, columns = db_het.columns)\n",
    "    \n",
    "    twopq.index = db_het.index\n",
    "    twopqs.append(twopq)\n",
    "\n",
    "    decoder, history = maf_prediction(bottle, db_minor, epoch, patience)\n",
    "    q2 = decoder(tf.convert_to_tensor(bottle, dtype=tf.float32))\n",
    "    q2 = pd.DataFrame(data=q2, columns = db_minor.columns)\n",
    "    \n",
    "    q2.index = db_minor.index\n",
    "    q2s.append(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588e47d-0a6c-4e94-bc44-4a945c77513d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da31282a-d70c-416e-9ade-71611df1071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output_global = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/\"\n",
    "p2 = pd.concat(p2s, axis=1)\n",
    "p2 = p2.sort_index()\n",
    "p2 = p2[list(complete.columns)]\n",
    "\n",
    "p2.to_pickle(f\"{path_output_global}/esti_p2_zoom_0_via_esti_pop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e95caff3-360b-45fe-b0b3-3cf843e31c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = pd.concat(q2s, axis=1)\n",
    "q2 = q2.sort_index()\n",
    "q2 = q2[list(complete.columns)]\n",
    "q2.to_pickle(f\"{path_output_global}/esti_q2_zoom_0_via_esti_pop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a02ca88-8784-4d4c-ae9a-6c948b95521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "twopq = pd.concat(twopqs, axis=1)\n",
    "twopq = twopq.sort_index()\n",
    "twopq = twopq[list(complete.columns)]\n",
    "twopq.to_pickle(f\"{path_output_global}/esti_2pq_zoom_0_via_esti_pop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccc7d6-6329-436e-a5db-8b7027738197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74111670-7666-4d58-8cb9-e6903aa5266e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be0d328-e6dd-4a05-bb7e-843bd1607c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
