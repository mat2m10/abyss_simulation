{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b16a562-1e8a-4da1-92ce-832736292997",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad9af2a-7865-4c65-9148-dfb74a6bbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from helpers import parse_variables\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedcde92-ecb6-426f-8088-11ba48c8dbbd",
   "metadata": {},
   "source": [
    "# Extracting simulated data from rstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81f6584-fa24-4f9b-9c28-aa95e0df4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = parse_variables('geno_simulation.txt')\n",
    "G = int(dict['G'])\n",
    "L = int(dict['L'])\n",
    "c = int(dict['c'])\n",
    "k = int(dict['k'])\n",
    "M = float(dict['M'])\n",
    "HWE = float(dict['HWE'])\n",
    "\n",
    "# Thresholds\n",
    "very_rare_threshold_L = float(dict['very_rare_threshold_L'])\n",
    "very_rare_threshold_H = float(dict['very_rare_threshold_H'])\n",
    "\n",
    "rare_threshold_L = float(dict['rare_threshold_L'])\n",
    "rare_threshold_H = float(dict['rare_threshold_H'])\n",
    "\n",
    "common_threshold_L = float(dict['common_threshold_L'])\n",
    "common_threshold_H = float(dict['common_threshold_H'])\n",
    "\n",
    "file = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/raw/simulated_genotypes_G{G}_L{L}_c{c}_k{k}_M{M}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e212ac4-7396-4ee8-9c0f-b2dda7b7d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_simulated_file = \"./\"+ file\n",
    "number_of_loci = G*L\n",
    "number_of_individuals = c*k*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada410be-cda1-4be3-bb3d-5095c8f662c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_loci= pd.read_csv(path_simulated_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43243b4-87ab-4d91-9a12-b0f9f6a7f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_populations = k*k\n",
    "labels_pop = []\n",
    "for i in range(number_of_populations):\n",
    "    labels_pop += [i+1]*c\n",
    "\n",
    "simulated_loci[\"populations\"] = labels_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1400a8d-44c3-4aca-a9bc-2348c74b3abc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "probabilities are not non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m     freq_het \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mfreq_maj)\n\u001b[1;32m     49\u001b[0m     freq_min \u001b[38;5;241m=\u001b[39m freq_maj\n\u001b[0;32m---> 50\u001b[0m     pop_geno \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnr_maj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnr_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfreq_maj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_het\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_min\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     temp_pop[col] \u001b[38;5;241m=\u001b[39m pop_geno\n\u001b[1;32m     53\u001b[0m dfs\u001b[38;5;241m.\u001b[39mappend(temp_pop)\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:973\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities are not non-negative"
     ]
    }
   ],
   "source": [
    "unique_pops = list(set(labels_pop))\n",
    "unique_pops.sort()\n",
    "dfs = []\n",
    "if HWE == 1:\n",
    "    for pop in unique_pops:\n",
    "        temp_pop = simulated_loci[simulated_loci[\"populations\"] == pop]\n",
    "        temp_pop = temp_pop.drop('populations', axis=1)\n",
    "        for col in temp_pop.columns:\n",
    "            # Check if the column has only one unique value\n",
    "            if temp_pop[col].nunique() == 1:\n",
    "                # Randomly select a row index\n",
    "                random_index = np.random.choice(temp_pop.index)\n",
    "                # Flip the value in that row and column\n",
    "                temp_pop.at[random_index, col] = 1 - temp_pop.at[random_index, col]\n",
    "    \n",
    "            nr_maj = temp_pop[col].value_counts().get(1, 0)\n",
    "            nr_min = temp_pop[col].value_counts().get(0, 0)\n",
    "            q = nr_min/(nr_maj + nr_min)\n",
    "            if q > 0.5:\n",
    "                q = 1-q\n",
    "    \n",
    "            p = 1-q\n",
    "            freq_maj = p ** 2\n",
    "            freq_het = 2 * p * q\n",
    "            freq_min = q ** 2\n",
    "            pop_geno = np.random.choice([1.0, 0.0, -1.0], size=nr_maj + nr_min, p=[freq_maj, freq_het, freq_min])\n",
    "    \n",
    "            temp_pop[col] = pop_geno\n",
    "        dfs.append(temp_pop)\n",
    "\n",
    "else:\n",
    "    for pop in unique_pops:\n",
    "        temp_pop = simulated_loci[simulated_loci[\"populations\"] == pop]\n",
    "        temp_pop = temp_pop.drop('populations', axis=1)\n",
    "        for col in temp_pop.columns:\n",
    "            # Check if the column has only one unique value\n",
    "            if temp_pop[col].nunique() == 1:\n",
    "                # Randomly select a row index\n",
    "                random_index = np.random.choice(temp_pop.index)\n",
    "                # Flip the value in that row and column\n",
    "                temp_pop.at[random_index, col] = 1 - temp_pop.at[random_index, col]\n",
    "    \n",
    "            nr_maj = temp_pop[col].value_counts().get(1, 0)\n",
    "            nr_min = temp_pop[col].value_counts().get(0, 0)\n",
    "            q = nr_min/(nr_maj + nr_min)\n",
    "\n",
    "            freq_maj = q ** 2\n",
    "            freq_het = 1-(2*freq_maj)\n",
    "            freq_min = freq_maj\n",
    "            pop_geno = np.random.choice([1.0, 0.0, -1.0], size=nr_maj + nr_min, p=[freq_maj, freq_het, freq_min])\n",
    "    \n",
    "            temp_pop[col] = pop_geno\n",
    "        dfs.append(temp_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119d581-ffec-40d3-b175-4de2b762fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_genotype = pd.concat(dfs, axis=0)+1\n",
    "simulated_genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf5129-26e5-445d-90cc-b694185b1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate when AF is > 0.5 and change the genotype\n",
    "# Initialize a dictionary to store allele frequencies\n",
    "allele_frequencies = {}\n",
    "\n",
    "# Calculate allele frequencies for each SNP column\n",
    "for snp in simulated_genotype.columns:\n",
    "    total_alleles = 2 * len(simulated_genotype[snp])  # Total number of alleles (2 alleles per sample)\n",
    "    minor_allele_count = (2 * simulated_genotype[snp].value_counts().get(0, 0)) + simulated_genotype[snp].value_counts().get(1, 0)\n",
    "    allele_frequency = minor_allele_count / total_alleles\n",
    "    allele_frequencies[snp] = allele_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484a26b-19fc-42e4-b9ec-3274aca58d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = simulated_genotype.T\n",
    "temp['AFs'] = allele_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d20977-a1bd-4fb9-bd52-f8e81030e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e0cd1-4671-4cd5-9f19-29107ef4f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to flip 0s to 2s and 2s to 0s\n",
    "def flip_genotypes(row):\n",
    "    if row['AFs'] > 0.5:\n",
    "        # Apply transformation for the condition\n",
    "        row[:-1] = row[:-1].replace({0: 2, 2: 0})\n",
    "        row['AFs'] = 1 - row['AFs']  # Adjust allele frequency\n",
    "    return row\n",
    "\n",
    "# Apply the function across the DataFrame, row-wise\n",
    "df_transformed = temp.apply(flip_genotypes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd555f3a-9be8-4534-8026-76e519b85d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691c8c6-a1f6-4695-89aa-e814ee68c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_genotype = df_transformed.drop('AFs', axis=1).T\n",
    "columns_to_drop  = simulated_genotype.columns[simulated_genotype.nunique() == 1] # If double columns delete it \n",
    "simulated_genotype = simulated_genotype.drop(columns=columns_to_drop)\n",
    "simulated_genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3cb01-8b40-4b55-9bcf-c55e8d345204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_all_genotypes(series, genotypes={0.0, 1.0, 2.0}):\n",
    "    return genotypes.issubset(series.unique())\n",
    "\n",
    "simulated_genotype = simulated_genotype[[col for col in simulated_genotype.columns if contains_all_genotypes(simulated_genotype[col])]]\n",
    "simulated_genotype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7929e-1a91-4e41-85b8-61c432b07606",
   "metadata": {},
   "source": [
    "# Recalculate AFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b345f-3742-42f9-8fb1-25576d3b488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate when AF is > 0.5 and change the genotype\n",
    "# Initialize a dictionary to store allele frequencies\n",
    "allele_frequencies = {}\n",
    "\n",
    "# Calculate allele frequencies for each SNP column\n",
    "for snp in simulated_genotype.columns:\n",
    "    total_alleles = 2 * len(simulated_genotype[snp])  # Total number of alleles (2 alleles per sample)\n",
    "    minor_allele_count = (2 * simulated_genotype[snp].value_counts().get(0, 0)) + simulated_genotype[snp].value_counts().get(1, 0)\n",
    "    allele_frequency = minor_allele_count / total_alleles\n",
    "    allele_frequencies[snp] = allele_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfaeb81-a86c-488f-8225-7fcca3ad7957",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = simulated_genotype.T\n",
    "temp['AFs'] = allele_frequencies\n",
    "AFs = temp[['AFs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3e13c-4ee2-4995-8c74-ec1c04a7db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare = temp[(temp['AFs'] > very_rare_threshold_L) & (temp['AFs'] <= very_rare_threshold_H)]\n",
    "rare = temp[(temp['AFs'] > rare_threshold_L) & (temp['AFs'] <= rare_threshold_H)]\n",
    "common = temp[(temp['AFs'] > common_threshold_L) & (temp['AFs'] <= common_threshold_H)]\n",
    "\n",
    "very_rare['snps'] = very_rare.index + '_AF_' + very_rare['AFs'].astype(str)\n",
    "very_rare.set_index('snps', inplace=True)\n",
    "very_rare_to_save = very_rare.drop('AFs', axis=1).T\n",
    "very_rare_afs = very_rare[['AFs']]\n",
    "\n",
    "rare['snps'] = rare.index + '_AF_' + rare['AFs'].astype(str)\n",
    "rare.set_index('snps', inplace=True)\n",
    "rare_to_save = rare.drop('AFs', axis=1).T\n",
    "rare_afs = rare[['AFs']]\n",
    "\n",
    "common['snps'] = common.index + '_AF_' + common['AFs'].astype(str)\n",
    "common.set_index('snps', inplace=True)\n",
    "common_to_save = common.drop('AFs', axis=1).T\n",
    "common_afs = common[['AFs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15401526-2c9c-461c-ab28-9ee90e44fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare_to_save.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/02_veryrare_genotype_AF_{very_rare_threshold_L}_{very_rare_threshold_H}.pkl\")\n",
    "rare_to_save.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/02_rare_genotype_AF_{rare_threshold_L}_{rare_threshold_H}.pkl\")\n",
    "common_to_save.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/02_common_genotype_AF_{common_threshold_L}_{common_threshold_H}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31360ed-5db3-495a-8277-671c80b8bb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ff66c-d54a-4a98-8770-2b92d1a352c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55306b-a7eb-401a-88d1-6350108b612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare_to_save = very_rare_to_save.rename(columns=lambda x: 'VR' + x)/2\n",
    "rare_to_save = rare_to_save.rename(columns=lambda x: 'R' + x)/2\n",
    "common_to_save = common_to_save.rename(columns=lambda x: 'C' + x)/2\n",
    "complete = pd.concat([common_to_save, rare_to_save, very_rare_to_save], axis=1)\n",
    "complete = ((complete*2)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ba6d8-b830-47e1-9ab0-0fb2a9b98655",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"rm data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/complete_truep2.pkl\")\n",
    "os.system(f\"rm data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/complete_truetwopq.pkl\")\n",
    "os.system(f\"rm data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/complete_trueq2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f7697-c92a-4128-82eb-82118c19b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete['pop'] = labels_pop\n",
    "\n",
    "p2s_dfs = []\n",
    "q2s_dfs = []\n",
    "twopqs_dfs = []\n",
    "\n",
    "for pop in list(complete['pop'].unique()):\n",
    "    snps = []\n",
    "    p2s = []\n",
    "    twopqs = []\n",
    "    q2s = []\n",
    "    temp = complete[complete['pop'] == pop].copy()\n",
    "    temp = temp.drop(\"pop\", axis=1)  # Use drop without inplace to avoid warnings\n",
    "    for snp in list(temp.columns):\n",
    "        try:\n",
    "            num_maj = temp[[snp]].value_counts()[1.0]\n",
    "        except Exception as e:\n",
    "            num_maj = 0 \n",
    "        try:\n",
    "            num_het = temp[[snp]].value_counts()[0.0]\n",
    "        except Exception as e:\n",
    "            num_het = 0\n",
    "        try:\n",
    "            num_min = temp[[snp]].value_counts()[-1.0]\n",
    "        except Exception as e:\n",
    "            num_min = 0\n",
    "        total_humans = num_maj + num_het + num_min\n",
    "        p2 = [num_maj / total_humans] * total_humans\n",
    "        twopq = [num_het / total_humans] * total_humans\n",
    "        q2 = [num_min / total_humans] * total_humans\n",
    "        p2s.append(p2)\n",
    "        twopqs.append(twopq)\n",
    "        q2s.append(q2)\n",
    "        snps.append(snp)\n",
    "    p2s = pd.DataFrame(p2s).T\n",
    "    p2s.index = temp.index\n",
    "    p2s.columns = snps\n",
    "\n",
    "    twopqs = pd.DataFrame(twopqs).T\n",
    "    twopqs.index = temp.index\n",
    "    twopqs.columns = snps\n",
    "\n",
    "    q2s = pd.DataFrame(q2s).T\n",
    "    q2s.index = temp.index\n",
    "    q2s.columns = snps\n",
    "\n",
    "    p2s_dfs.append(p2s)\n",
    "    twopqs_dfs.append(twopqs)\n",
    "    q2s_dfs.append(q2s)\n",
    "\n",
    "complete = complete.drop(\"pop\", axis=1)  # Use drop without inplace\n",
    "\n",
    "true_p2s = pd.concat(p2s_dfs)\n",
    "true_twopqs = pd.concat(twopqs_dfs)\n",
    "true_q2s = pd.concat(q2s_dfs)\n",
    "\n",
    "true_p2s.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/true_p2_via_true_pop.pkl\")\n",
    "true_twopqs.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/true_twopq_via_true_pop.pkl\")\n",
    "true_q2s.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/true_q2_via_true_pop.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657b258-9751-48ec-8d05-b66ac1ef7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"rm -rf data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/raw/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
