{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952ecdb1-1559-4457-9e41-8101eee023d9",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18f3ed-e1d2-4820-823a-077161431e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 14:11:27.898357: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-09 14:11:28.153254: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-09 14:11:28.496524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-09 14:11:28.779922: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-09 14:11:28.781358: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-09 14:11:29.172004: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "\n",
    "from helpers import parse_variables, get_risk_level, map_to_color, simulate_quant_trait\n",
    "from models import ols_regression, manhattan_linear, gc\n",
    "from deep_learning_models import abyss, deep_abyss\n",
    "\n",
    "import warnings\n",
    "from scipy.stats import t\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66c22e-4f39-4950-ba74-f93d051b1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "naming_dict = {\n",
    "    \"no_risk\": \"no environmental risk\",\n",
    "    \"NW_risk\": \"Smooth linear North-West environmental risk\",\n",
    "    \"N_risk\" : \"Smooth linear North environmental risk\",\n",
    "    \"blob_risk\": \"Localised big blob risk\",\n",
    "    \"center_risk\": \"Localised big central risk\",\n",
    "    \"big_square_risk\": \"big square risk\",\n",
    "    \"square_risk\" : \"Tiny square risk\",\n",
    "    'hi_square_risk' : \"Tiny square risk\",\n",
    "    \"hi_gauss_blob_risk\": \"Global Gaussian Risk\",\n",
    "    \"two_square_risk\": \"Two tiny risks\",\n",
    "    \"gauss_blob_risk\" : \"Gaussian Risk\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a036829-d9a2-40e7-8c7b-88df343b3d98",
   "metadata": {},
   "source": [
    "# Load genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e226cd5-985a-4b17-98ac-7bd9d3e34980",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = parse_variables('geno_simulation.txt')\n",
    "G = int(dict['G'])\n",
    "L = int(dict['L'])\n",
    "c = int(dict['c'])\n",
    "k = int(dict['k'])\n",
    "M = float(dict['M'])\n",
    "\n",
    "# Thresholds\n",
    "very_rare_threshold_L = float(dict['very_rare_threshold_L'])\n",
    "very_rare_threshold_H = float(dict['very_rare_threshold_H'])\n",
    "\n",
    "rare_threshold_L = float(dict['rare_threshold_L'])\n",
    "rare_threshold_H = float(dict['rare_threshold_H'])\n",
    "\n",
    "common_threshold_L = float(dict['common_threshold_L'])\n",
    "common_threshold_H = float(dict['common_threshold_H'])\n",
    "\n",
    "number_of_snps = (G*L)/2 # one loci per chromosome\n",
    "number_of_individuals = c*k*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e96d99-38c6-4660-aa7c-0ab84e8d765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_veryrare_genotype_AF_{very_rare_threshold_L}_{very_rare_threshold_H}.pkl\")\n",
    "rare = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_rare_genotype_AF_{rare_threshold_L}_{rare_threshold_H}.pkl\")\n",
    "common = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_common_genotype_AF_{common_threshold_L}_{common_threshold_H}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6d015-560b-4ed3-bd5e-08ee0eb913ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare = very_rare.rename(columns=lambda x: 'VR' + x)/2\n",
    "rare = rare.rename(columns=lambda x: 'R' + x)/2\n",
    "common = common.rename(columns=lambda x: 'C' + x)/2\n",
    "complete = pd.concat([common, rare, very_rare], axis=1)\n",
    "complete = ((complete*2)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda82e66-40fe-415f-a176-3da5900c4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete['CG2_AF_0.4634'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a7340-37c6-489a-aabc-22ee24db330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b9431-8424-44eb-8c7d-113df5de4880",
   "metadata": {},
   "source": [
    "# Load populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474b96a-a67b-461c-9f64-a9d9b7d28c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/phenotype/01_population_structure.pkl\")\n",
    "populations['population_number'] = populations['populations'].str.extract('(\\d+)').astype(int)\n",
    "# Calculating X and Y coordinates\n",
    "populations['x'] = ((populations['population_number'] - 1) % k) + 1\n",
    "populations['y'] = ((populations['population_number'] - 1) // k) + 1\n",
    "populations['z'] = 0.5\n",
    "populations['population'] = populations['population_number']/(k*k)\n",
    "palette = [map_to_color(x, y, z, populations) for x, y, z in zip(populations['x'], populations['y'], populations['z'])]\n",
    "\n",
    "# Check the grid\n",
    "df_agg = populations.groupby(['x', 'y']).agg({'population': 'mean'}).reset_index()\n",
    "\n",
    "# Now, pivot the aggregated DataFrame\n",
    "grid_df = df_agg.pivot(index='y', columns='x', values='population')\n",
    "\n",
    "\n",
    "heatmap = sns.heatmap(grid_df, cmap=palette, linewidths=.5, square=True, cbar=False)\n",
    "\n",
    "# Add a title to the heatmap\n",
    "plt.title('Population Grid', fontsize=16)\n",
    "plt.gca().invert_yaxis()  # Sometimes it's necessary to invert the y-axis for correct orientation\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e03c4f-4474-4db3-be9b-962f19de9514",
   "metadata": {},
   "source": [
    "# True maf per populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d7c29-02b8-4130-a6c7-6ad99a99441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_population_maf_dfs = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/complete_truemafperpop.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d018f2f3-543c-45dd-a009-77bf35fe1854",
   "metadata": {},
   "source": [
    "# Create snp effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba22270-48a0-41e4-9a4e-371b8ed80382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi(arr, effectsize):\n",
    "    return [1 * (num + 0.001) * effectsize for num in arr]\n",
    "\n",
    "def divi(arr, effectsize):\n",
    "    return [(1 / (num + 0.001)) * effectsize for num in arr]\n",
    "\n",
    "effectsize = 1\n",
    "numbers_af = [float(col.split('_AF_')[1]) for col in common.columns if '_AF_' in col]\n",
    "snp_names = [col.split('_AF_')[0] for col in common.columns if '_AF_' in col]\n",
    "\n",
    "beta_values = divi(numbers_af, effectsize)\n",
    "data = {'snp': snp_names, 'Beta': beta_values}\n",
    "beta_common = pd.DataFrame(data)\n",
    "beta_common['maf'] = \"common\"\n",
    "\n",
    "numbers_af = [float(col.split('_AF_')[1]) for col in rare.columns if '_AF_' in col]\n",
    "snp_names = [col.split('_AF_')[0] for col in rare.columns if '_AF_' in col]\n",
    "\n",
    "beta_values = divi(numbers_af, effectsize)\n",
    "data = {'snp': snp_names, 'Beta': beta_values}\n",
    "beta_rare = pd.DataFrame(data)\n",
    "beta_rare['maf'] = \"rare\"\n",
    "\n",
    "numbers_af = [float(col.split('_AF_')[1]) for col in very_rare.columns if '_AF_' in col]\n",
    "snp_names = [col.split('_AF_')[0] for col in very_rare.columns if '_AF_' in col]\n",
    "\n",
    "beta_values = divi(numbers_af, effectsize)\n",
    "data = {'snp': snp_names, 'Beta': beta_values}\n",
    "beta_very_rare = pd.DataFrame(data)\n",
    "beta_very_rare['maf'] = \"very rare\"\n",
    "\n",
    "betas = pd.concat([beta_common, beta_rare, beta_very_rare], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574ec5d-e63c-4eae-94c8-712b2182614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_snps = list(complete.columns)\n",
    "phenos_mono = []\n",
    "for snp in all_snps:\n",
    "    index_snp = snp.split('_')[0]\n",
    "    beta_value = betas.loc[betas['snp'] == index_snp, 'Beta'].values[0]\n",
    "    phenos_mono.append(complete[snp] * beta_value)\n",
    "\n",
    "# Converting phenos_mono list of series to DataFrame directly\n",
    "phenos_mono = pd.concat(phenos_mono, axis=1)\n",
    "phenos_mono.columns = complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1552963-14b9-4d1b-948a-ef438969e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_var = phenos_mono.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8a95a-ee78-4f8e-9c96-567f584ce81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(phenos_mono)\n",
    "for snp in list(phenos_mono.columns):\n",
    "    var_effect = np.var(phenos_mono[snp])\n",
    "    total_variance = var_effect / 0.001\n",
    "    var_noise = total_variance - var_effect\n",
    "    sd_noise = np.sqrt(var_noise)\n",
    "    # Generate phenotype with noise\n",
    "    phenos_mono[snp] = phenos_mono[snp] + np.random.normal(0, sd_noise, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae22323-69b4-4f02-88d6-ebf324fc62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = phenos_mono.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc4ac40-2ccd-42e4-8d1f-9d7888f88c52",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d29833-1220-4e7a-a537-0123b9c2b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta1 * X  = y (should be the best)\n",
    "b1x__y = manhattan_linear(complete, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a77333-d41c-4cd5-94c5-771f5f99ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta1 * X + betas * pop_coordinates = y\n",
    "b1x_b2pop__y = manhattan_linear(complete, y, populations[['x','y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c36ab-defc-476b-8760-9acd60e5a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = true_population_maf_dfs.copy()\n",
    "p = 1-q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecbe49-7beb-4e99-8ba7-038565f65c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta1 * (X - (p-q)) + betas * pop_coordinates = y\n",
    "b1xcorr_b2pop__y = manhattan_linear(complete-(p-q), y, populations[['x','y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38152c5b-9362-4ad7-b025-3a5e8ca63d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta1 * (X - (p-q)) + betas * pop_coordinates = y\n",
    "b1xcorr_b2pop__y = manhattan_linear(complete, y, populations[['x','y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e58150-6566-4ba0-9b6e-939ebc012128",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_common_PCs = 35\n",
    "pc_columns = ['PC{}'.format(i) for i in range(1, nr_common_PCs+1)]\n",
    "PC_common= pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/phenotype/PCs/common_genotype_AF_{common_threshold_L}_{common_threshold_H}.pkl\")\n",
    "PC_common= PC_common[pc_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67851b23-2154-440a-810a-fb003787b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta1 * (X + betas * PCs = y\n",
    "b1xcorr_b2pcs__y = manhattan_linear(complete, y, PC_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636abea1-d1b6-4766-a7a9-efac210dc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid overcorrection\n",
    "y_mono = y[['CG1_AF_0.49585']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f6bee-e555-47cd-90a7-ebd87ec41316",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30625f-ce32-45da-8a2a-8aca74952a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Standardize the data\n",
    "y_preds = []\n",
    "y_names = []\n",
    "scaler = StandardScaler()\n",
    "PC_scaled = scaler.fit_transform(PC_common)\n",
    "i = 0\n",
    "for phenotype in list(y.columns):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(PC_scaled, y[[phenotype]], test_size=0.2, random_state=42)\n",
    "    # Build the feed-forward neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=nr_common_PCs, activation='elu'))\n",
    "    model.add(Dense(1, activation='linear'))  # Assuming regression problem; use 'sigmoid' or 'softmax' for classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    # Define early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_split=0.2, \n",
    "                        callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    # Predicting using the model (optional)\n",
    "    y_pred = model.predict(PC_scaled)\n",
    "    y_preds.append(y_pred.flatten())\n",
    "    y_names.append(phenotype)\n",
    "    print(f\"{np.round(i/len(list(y.columns)),2)}%\")\n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed241a-58cf-45d4-b01d-24a8204c15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc03991-865b-4d12-b18d-970c6a95a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113175dc-dd66-4771-932f-4bc55ce220a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caeb207-3618-413c-922c-b41f48fb1740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486ec9e-ab62-4961-ab38-8cef086e16d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ad727-124c-448d-adc3-4c89b9e24a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b219dde-1db1-48b6-bc3c-3aa890e84e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b4f37-c9d8-4303-b9ac-d75eb1718f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QQ plot\n",
    "df_bests = pd.DataFrame()\n",
    "df_bests[\"-logP_no_cov\"] = np.sort(b1x__y['-logPs'])\n",
    "df_bests[\"-logP_true_pops_as_cov\"] = np.sort(b1x_b2pop__y['-logPs'])\n",
    "df_bests[\"-logP_true_pops_as_cov_X_corrected\"] = np.sort(b1xcorr_b2pop__y['-logPs'])\n",
    "\n",
    "df_bests[\"-logP_Pcs_as_cov\"] = np.sort(b1xcorr_b2pcs__y['-logPs'])\n",
    "\n",
    "# Find the maximum value in the DataFrame excluding inf and NaN\n",
    "max_value = df_bests.replace([np.inf, -np.inf], np.nan).max().max()\n",
    "\n",
    "# Replace inf values with the maximum value found\n",
    "df_bests.replace([np.inf, -np.inf], max_value, inplace=True)\n",
    "\n",
    "# Replace NaN values with the maximum value found\n",
    "df_bests.fillna(max_value, inplace=True)\n",
    "n = len(df_bests)\n",
    "expected_quantiles = np.arange(1, n + 1) / n\n",
    "expected_logP = np.sort(-np.log10(expected_quantiles))\n",
    "df_bests['expected_logP'] = expected_logP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f4925-a320-4c5b-9064-9f26b81c7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='expected_logP', y='-logP_no_cov', data=df_bests, color='blue', label='No covariates', linewidth=0)\n",
    "\n",
    "sns.scatterplot(x='expected_logP', y='-logP_true_pops_as_cov', data=df_bests, color='purple', label='True population as cov', linewidth=0)\n",
    "\n",
    "sns.scatterplot(x='expected_logP', y='-logP_true_pops_as_cov_X_corrected', data=df_bests, color='darkred', label='True population as cov with genotype corrected', linewidth=0)\n",
    "\n",
    "sns.scatterplot(x='expected_logP', y='-logP_Pcs_as_cov', data=df_bests, color='darkgreen', label='PC as cov', linewidth=0)\n",
    "\n",
    "# Plot diagonal reference line\n",
    "plt.plot([min(df_bests['expected_logP']), max(df_bests['expected_logP'])], \n",
    "         [min(df_bests['expected_logP']), max(df_bests['expected_logP'])], \n",
    "         color='red', linestyle='--')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Expected')\n",
    "plt.ylabel('-Log10(P) Values')\n",
    "plt.title(f\"QQ Plot of Log Values\")\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "#plt.savefig(f\"data/plots/qq_pheno_{name_risk}_iter_{iterations}_G{G}_L{L}_c{c}_k{k}_M{M}.png\", dpi=100)\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1fdec3-917b-41f3-9938-5d5a2bbf2f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0bdaf-f099-4ab3-99e3-45d5e43fd221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
