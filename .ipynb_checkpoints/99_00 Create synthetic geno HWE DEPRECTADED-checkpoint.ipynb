{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af578b8-9e30-4da2-9efd-e91c6b015bf0",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d7b076-e197-434d-9a61-22c9b87786cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from helpers import parse_variables\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cabd789-0312-4a85-a9bd-b995fd0497fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = parse_variables('geno_simulation.txt')\n",
    "G = int(dict['G'])\n",
    "L = int(dict['L'])\n",
    "c = int(dict['c'])\n",
    "k = int(dict['k'])\n",
    "M = float(dict['M'])\n",
    "\n",
    "# Thresholds\n",
    "very_rare_threshold_L = float(dict['very_rare_threshold_L'])\n",
    "very_rare_threshold_H = float(dict['very_rare_threshold_H'])\n",
    "\n",
    "rare_threshold_L = float(dict['rare_threshold_L'])\n",
    "rare_threshold_H = float(dict['rare_threshold_H'])\n",
    "\n",
    "common_threshold_L = float(dict['common_threshold_L'])\n",
    "common_threshold_H = float(dict['common_threshold_H'])\n",
    "\n",
    "os.makedirs(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype\",exist_ok = True)\n",
    "path_data = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/01_raw.csv\"\n",
    "path_simulated_file = f\"{path_data}\"\n",
    "number_of_alleles = G*L\n",
    "number_of_snps = (G*L)/2\n",
    "number_of_individuals = c*k*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d65cc7-15e5-4346-bced-0ee93c23786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pair SNPs and summarize genotype\n",
    "def summarize_genotypes(df):\n",
    "    summarized_genotypes = {}\n",
    "    # Iterate over pairs of columns\n",
    "    for i in range(1, df.shape[1], 2):\n",
    "        pair_sum = df.iloc[:, i-1] + df.iloc[:, i]\n",
    "        # Apply the genotype summarization logic\n",
    "        summarized_genotypes[f'G{i//2 + 1}'] = np.where(pair_sum == 2, 2, pair_sum)\n",
    "    return pd.DataFrame(summarized_genotypes)\n",
    "\n",
    "# Function to flip 0s to 2s and 2s to 0s\n",
    "def flip_genotypes(row):\n",
    "    if row['AFs'] > 0.5:\n",
    "        # Apply transformation for the condition\n",
    "        row[:-1] = row[:-1].replace({0: 2, 2: 0})\n",
    "        row['AFs'] = 1 - row['AFs']  # Adjust allele frequency\n",
    "    return row\n",
    "\n",
    "\n",
    "def hwe_test(genotypes):\n",
    "    \"\"\"\n",
    "    Perform a chi-square test for Hardy-Weinberg Equilibrium.\n",
    "    Returns p-value of the test.\n",
    "    \"\"\"\n",
    "    # Count genotype frequencies\n",
    "    obs_aa = sum(genotypes == 0)\n",
    "    obs_ab = sum(genotypes == 1)\n",
    "    obs_bb = sum(genotypes == 2)\n",
    "    total = obs_aa + obs_ab + obs_bb\n",
    "\n",
    "    # Calculate allele frequencies\n",
    "    p = (2 * obs_aa + obs_ab) / (2 * total)\n",
    "    q = 1 - p\n",
    "\n",
    "    # Expected genotype frequencies\n",
    "    exp_aa = total * p**2\n",
    "    exp_ab = total * 2 * p * q\n",
    "    exp_bb = total * q**2\n",
    "\n",
    "    # Avoid zero expected counts by using a small value (e.g., 1e-10)\n",
    "    expected = np.array([exp_aa, exp_ab, exp_bb])\n",
    "    expected[expected == 0] = 1e-10\n",
    "\n",
    "    observed = np.array([obs_aa, obs_ab, obs_bb])\n",
    "    \n",
    "    # Chi-square test\n",
    "    chi2, p_value = stats.chisquare(f_obs=observed, f_exp=expected)\n",
    "\n",
    "    return p_value\n",
    "\n",
    "\n",
    "def contains_all_genotypes(series, genotypes={0.0, 1.0, 2.0}):\n",
    "    return genotypes.issubset(series.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e8a910-cac7-4830-8fa3-e062d80bbf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5408d2-ee12-4f1d-bee1-82b1ff2ff257",
   "metadata": {},
   "source": [
    "# Load simulation params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5317ffc-86b8-4c07-a655-8c7ab543621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_vars = {\n",
    "    \"very_rare\" : 250,\n",
    "    \"rare\" : 250,\n",
    "    \"common\" : 300,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d569d519-4acc-4f82-a9a7-16f323578ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_very_rare = pd.DataFrame()\n",
    "temp_rare = pd.DataFrame()\n",
    "temp_common = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e3e37-1495-4dcb-8ab4-cba807d836cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done at 0.0033333333333333335%\n",
      "Done at 0.0033333333333333335%\n",
      "Done at 0.0033333333333333335%\n",
      "Done at 0.006666666666666667%\n",
      "Done at 0.01%\n",
      "Done at 0.01%\n",
      "Done at 0.016666666666666666%\n",
      "Done at 0.02666666666666667%\n",
      "Done at 0.02666666666666667%\n",
      "Done at 0.03%\n",
      "Done at 0.03333333333333333%\n",
      "Done at 0.03666666666666667%\n",
      "Done at 0.04666666666666667%\n",
      "Done at 0.05%\n",
      "Done at 0.056666666666666664%\n",
      "Done at 0.056666666666666664%\n",
      "Done at 0.06333333333333334%\n",
      "Done at 0.06333333333333334%\n",
      "Done at 0.06333333333333334%\n",
      "Done at 0.06666666666666667%\n",
      "Done at 0.07666666666666666%\n",
      "Done at 0.08333333333333333%\n",
      "Done at 0.08666666666666667%\n"
     ]
    }
   ],
   "source": [
    "very_rare_nr = 0\n",
    "rare_nr = 0\n",
    "common_nr = 0\n",
    "\n",
    "condition1 = very_rare_nr < nr_vars[\"very_rare\"]\n",
    "condition2 = rare_nr < nr_vars[\"rare\"]\n",
    "condition3 = common_nr < nr_vars[\"common\"]\n",
    "\n",
    "while condition1 or condition2 or condition3:\n",
    "    \n",
    "    # Define the R commands to run, passing parameters as arguments\n",
    "    commands = [\n",
    "        f\"source('geno_simulation.txt')\",\n",
    "        f\"source('create_geno.R', echo=TRUE)\",\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    commands = [\n",
    "        \"source('geno_simulation.txt')\",\n",
    "        f\"G <- {G}\",\n",
    "        f\"L <- {L}\",\n",
    "        f\"c <- {c}\",\n",
    "        f\"k <- {k}\",\n",
    "        f\"M <- {M}\",\n",
    "        \"source('create_geno.R', echo=TRUE)\"\n",
    "    ]\n",
    "    \n",
    "    # Concatenate commands into a single string\n",
    "    r_script = \";\".join(commands)\n",
    "    \n",
    "    # Run the R script\n",
    "    result = subprocess.run(['Rscript', '-e', r_script], capture_output=True, text=True)\n",
    "    \n",
    "    # Print the output\n",
    "    #print(result.stdout)\n",
    "    \n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        #print(\"Error executing R script:\")\n",
    "        #print(result.stderr)\n",
    "        pass\n",
    "\n",
    "    os.system(f\"mv simulated_genotypes_G{G}_L{L}_c{c}_k{k}_M{M}.csv 01_raw.csv\")\n",
    "    os.system(f\"mv 01_raw.csv {path_simulated_file}\")\n",
    "\n",
    "\n",
    "\n",
    "    simulated_loci= pd.read_csv(path_simulated_file)\n",
    "\n",
    "    # Apply the function to the sample DataFrame\n",
    "    simulated_genotype = summarize_genotypes(simulated_loci)\n",
    "    columns_to_drop  = simulated_genotype.columns[simulated_genotype.nunique() == 1] # If double columns delete it \n",
    "    simulated_genotype = simulated_genotype.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "    # calculate when AF is > 0.5 and change the genotype\n",
    "    # Initialize a dictionary to store allele frequencies\n",
    "    allele_frequencies = {}\n",
    "    \n",
    "    # Calculate allele frequencies for each SNP column\n",
    "    for snp in simulated_genotype.columns:\n",
    "        total_alleles = 2 * len(simulated_genotype[snp])  # Total number of alleles (2 alleles per sample)\n",
    "        minor_allele_count = (2 * simulated_genotype[snp].value_counts().get(0, 0)) + simulated_genotype[snp].value_counts().get(1, 0)\n",
    "        allele_frequency = minor_allele_count / total_alleles\n",
    "        allele_frequencies[snp] = allele_frequency\n",
    "\n",
    "    temp = simulated_genotype.T\n",
    "    temp['AFs'] = allele_frequencies\n",
    "\n",
    "    df_transformed = temp.apply(flip_genotypes, axis=1)\n",
    "\n",
    "\n",
    "    simulated_genotype = df_transformed.drop('AFs', axis=1).T\n",
    "    columns_to_drop  = simulated_genotype.columns[simulated_genotype.nunique() == 1] # If double columns delete it \n",
    "    simulated_genotype = simulated_genotype.drop(columns=columns_to_drop)\n",
    "\n",
    "    simulated_genotype = simulated_genotype[[col for col in simulated_genotype.columns if contains_all_genotypes(simulated_genotype[col])]]\n",
    "\n",
    "    # Threshold for HWE p-value\n",
    "    threshold = 0.99\n",
    "    \n",
    "    number_of_populations = k*k\n",
    "    labels_pop = []\n",
    "    for i in range(number_of_populations):\n",
    "        labels_pop += [f\"pop {i+1}\"]*c\n",
    "\n",
    "    simulated_genotype[\"populations\"] = labels_pop\n",
    "\n",
    "\n",
    "    hwe_dfs = []\n",
    "    unique_pops = list(set(labels_pop))\n",
    "    for pop in unique_pops:\n",
    "        temp_pop = simulated_genotype[simulated_genotype[\"populations\"] == pop]\n",
    "        temp_pop = temp_pop.drop('populations', axis=1)\n",
    "        # List to hold columns in HWE\n",
    "        hwe_columns = []\n",
    "        \n",
    "        for column in temp_pop.columns:\n",
    "            p_value = hwe_test(temp_pop[column].values)\n",
    "            if p_value > threshold:\n",
    "                hwe_columns.append(column)\n",
    "        cols_in_hwe = temp_pop[hwe_columns]\n",
    "        hwe_dfs.append(cols_in_hwe)\n",
    "\n",
    "    combined_df = pd.concat(hwe_dfs, axis=0)\n",
    "\n",
    "    sorted_df = combined_df.sort_index()\n",
    "    # Drop columns with any NaN values\n",
    "    sorted_df.fillna(2.0, inplace=True)\n",
    "    simulated_genotype = sorted_df\n",
    "\n",
    "    # calculate when AF is > 0.5 and change the genotype\n",
    "    # Initialize a dictionary to store allele frequencies\n",
    "    allele_frequencies = {}\n",
    "    \n",
    "    # Calculate allele frequencies for each SNP column\n",
    "    for snp in simulated_genotype.columns:\n",
    "        total_alleles = 2 * len(simulated_genotype[snp])  # Total number of alleles (2 alleles per sample)\n",
    "        minor_allele_count = (2 * simulated_genotype[snp].value_counts().get(0, 0)) + simulated_genotype[snp].value_counts().get(1, 0)\n",
    "        allele_frequency = minor_allele_count / total_alleles\n",
    "        allele_frequencies[snp] = allele_frequency\n",
    "\n",
    "\n",
    "    temp = simulated_genotype.T\n",
    "    temp['AFs'] = allele_frequencies\n",
    "    AFs = temp[['AFs']]\n",
    "\n",
    "    very_rare = temp[(temp['AFs'] > very_rare_threshold_L) & (temp['AFs'] <= very_rare_threshold_H)]\n",
    "    rare = temp[(temp['AFs'] > rare_threshold_L) & (temp['AFs'] <= rare_threshold_H)]\n",
    "    common = temp[(temp['AFs'] > common_threshold_L) & (temp['AFs'] <= common_threshold_H)]\n",
    "    if temp_very_rare.shape[0] < nr_vars[\"very_rare\"]:\n",
    "        temp_very_rare = pd.concat([temp_very_rare, very_rare], ignore_index=True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if temp_rare.shape[0] < nr_vars[\"rare\"]:\n",
    "        temp_rare = pd.concat([temp_rare, rare], ignore_index=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if temp_common.shape[0] < nr_vars[\"common\"]:\n",
    "        temp_common = pd.concat([temp_common, common], ignore_index=True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    temp_very_rare = temp_very_rare.drop_duplicates()\n",
    "    temp_very_rare.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    temp_rare = temp_rare.drop_duplicates()\n",
    "    temp_rare.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    temp_common = temp_common.drop_duplicates()\n",
    "    temp_common.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Done at {temp_common.shape[0]/nr_vars['common']}%\")\n",
    "\n",
    "    very_rare_nr = temp_very_rare.shape[0]\n",
    "    rare_nr = temp_rare.shape[0]\n",
    "    common_nr = temp_common.shape[0]\n",
    "\n",
    "    condition1 = very_rare_nr < nr_vars[\"very_rare\"]\n",
    "    condition2 = rare_nr < nr_vars[\"rare\"]\n",
    "    condition3 = common_nr < nr_vars[\"common\"]\n",
    "\n",
    "\n",
    "\n",
    "very_rare = temp_very_rare.copy()\n",
    "rare = temp_rare.copy()\n",
    "common = temp_common.copy()\n",
    "\n",
    "very_rare['snps'] = very_rare.index.astype(str) + '_AF_' + very_rare['AFs'].astype(str)\n",
    "very_rare.set_index('snps', inplace=True)\n",
    "very_rare_to_save = very_rare.drop('AFs', axis=1).T\n",
    "very_rare_afs = very_rare[['AFs']]\n",
    "\n",
    "rare['snps'] = rare.index.astype(str) + '_AF_' + rare['AFs'].astype(str)\n",
    "rare.set_index('snps', inplace=True)\n",
    "rare_to_save = rare.drop('AFs', axis=1).T\n",
    "rare_afs = rare[['AFs']]\n",
    "\n",
    "common['snps'] = common.index.astype(str) + '_AF_' + common['AFs'].astype(str)\n",
    "common.set_index('snps', inplace=True)\n",
    "common_to_save = common.drop('AFs', axis=1).T\n",
    "common_afs = common[['AFs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1801bd-6408-41f4-83f1-556e9501409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc28bd7-a7e4-48ef-be85-4b5470d8c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_afs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc2063-f497-49de-abe9-1e65d507f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_genotype = pd.concat([very_rare_to_save, rare_to_save, common_to_save], axis=1)\n",
    "simulated_genotype.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_complete_genotypes_AF_0_0.5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719aee7e-b489-491b-90c7-997e8db3e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AFs = pd.concat([very_rare_afs, rare_afs, common_afs], axis=0)\n",
    "AFs.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_complete_frequencies_AF_0_0.5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1652d4a9-3614-45f1-bc35-3c9beaf7769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare_to_save.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_veryrare_genotype_AF_{very_rare_threshold_L}_{very_rare_threshold_H}.pkl\")\n",
    "rare_to_save.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_rare_genotype_AF_{rare_threshold_L}_{rare_threshold_H}.pkl\")\n",
    "common_to_save.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_common_genotype_AF_{common_threshold_L}_{common_threshold_H}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16a45f-ebc1-49a4-b212-ad4f7c61cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare_afs.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_veryrare_frequencies_AF_{very_rare_threshold_L}_{very_rare_threshold_H}.pkl\")\n",
    "rare_afs.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_rare_frequencies_AF_{rare_threshold_L}_{rare_threshold_H}.pkl\")\n",
    "common_afs.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/02_common_frequencies_AF_{common_threshold_L}_{common_threshold_H}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fbcb91-1b1f-4099-9cf6-b080e812abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"rm ./simulated*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d340528-f517-4d24-ada5-37ad46e3c07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
