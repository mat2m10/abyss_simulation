{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bae6b1-e426-4c39-8efa-ff56244f78ba",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fcd8df6-7319-4f11-ab41-d7057646f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from helpers import parse_variables\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b83405-35b8-452f-ba88-f957b71fa89b",
   "metadata": {},
   "source": [
    "# Load simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76388184-438d-41c0-a770-c343d1a79b24",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/G100_L100_c50_k4_M0.5_HWE1/genotype/01_veryrare_genotype_AF_0.0_0.05.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m number_of_snps \u001b[38;5;241m=\u001b[39m (G\u001b[38;5;241m*\u001b[39mL)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m# one loci per chromosome\u001b[39;00m\n\u001b[1;32m     24\u001b[0m number_of_individuals \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m*\u001b[39mk\u001b[38;5;241m*\u001b[39mk\n\u001b[0;32m---> 27\u001b[0m very_rare \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/G\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mG\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_L\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mL\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_c\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mc\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_k\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mk\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_M\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mM\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_HWE\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mHWE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/genotype/01_veryrare_genotype_AF_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvery_rare_threshold_L\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvery_rare_threshold_H\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m rare \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/G\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_L\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_c\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_k\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_M\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_HWE\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHWE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/genotype/01_rare_genotype_AF_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrare_threshold_L\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrare_threshold_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m common \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/G\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_L\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_c\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_k\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_M\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_HWE\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHWE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/genotype/01_common_genotype_AF_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommon_threshold_L\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommon_threshold_H\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/abyss_simul/lib/python3.10/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/abyss_simul/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/G100_L100_c50_k4_M0.5_HWE1/genotype/01_veryrare_genotype_AF_0.0_0.05.pkl'"
     ]
    }
   ],
   "source": [
    "dict = parse_variables('geno_simulation.txt')\n",
    "G = int(dict['G'])\n",
    "L = int(dict['L'])\n",
    "c = int(dict['c'])\n",
    "k = int(dict['k'])\n",
    "M = float(dict['M'])\n",
    "HWE = int(dict['HWE'])\n",
    "\n",
    "nr_humans = int(dict['nr_humans'])\n",
    "nr_snps = int(dict['nr_snps'])\n",
    "bottleneck_nr = int(dict['bottleneck_nr'])\n",
    "\n",
    "# Thresholds\n",
    "very_rare_threshold_L = float(dict['very_rare_threshold_L'])\n",
    "very_rare_threshold_H = float(dict['very_rare_threshold_H'])\n",
    "\n",
    "rare_threshold_L = float(dict['rare_threshold_L'])\n",
    "rare_threshold_H = float(dict['rare_threshold_H'])\n",
    "\n",
    "common_threshold_L = float(dict['common_threshold_L'])\n",
    "common_threshold_H = float(dict['common_threshold_H'])\n",
    "\n",
    "number_of_snps = (G*L)/2 # one loci per chromosome\n",
    "number_of_individuals = c*k*k\n",
    "\n",
    "\n",
    "very_rare = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_veryrare_genotype_AF_{very_rare_threshold_L}_{very_rare_threshold_H}.pkl\")\n",
    "rare = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_rare_genotype_AF_{rare_threshold_L}_{rare_threshold_H}.pkl\")\n",
    "common = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_common_genotype_AF_{common_threshold_L}_{common_threshold_H}.pkl\")\n",
    "\n",
    "very_rare = very_rare.rename(columns=lambda x: 'VR' + x)/2\n",
    "rare = rare.rename(columns=lambda x: 'R' + x)/2\n",
    "common = common.rename(columns=lambda x: 'C' + x)/2\n",
    "complete = pd.concat([common, rare, very_rare], axis=1)\n",
    "complete = ((complete*2)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2eb54-c4b4-45e4-b7b5-52ed1ad18ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bottle = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/phenotype/abyss_bottleneck\"\n",
    "bottle_file = [f for f in os.listdir(path_bottle) if int(f.split(\"_\")[2]) ==  bottleneck_nr][0]\n",
    "elapsed_time_bottleneck = float(bottle_file.split('_')[3].split('seconds')[0])\n",
    "bottle = pd.read_pickle(f\"{path_bottle}/{bottle_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a1100-f1dd-4ea7-9083-852ee51c20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25416ab7-401e-4f64-9229-e60427fc738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pops_estimated_lds = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/LD_blocks_estimated_mafs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15703e1-e4ed-4388-b25f-5fa25e3d09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "L*G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b8903-2e30-42fb-9218-c4146d3f0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2s_pop = []\n",
    "twopqs_pop = []\n",
    "p2s_pop = []\n",
    "\n",
    "for pop in os.listdir(path_pops_estimated_lds):\n",
    "    print(pop)\n",
    "    bottle_index = bottle[bottle['cluster']==int(pop)]\n",
    "    path_estimated_lds = path_pops_estimated_lds + \"/\" + pop\n",
    "    q2_files = [f for f in os.listdir(path_estimated_lds) if f.split(f\"_\")[6] == 'q2']\n",
    "    q2_files = sorted(q2_files, key=lambda x: int(x.split('_')[0]))\n",
    "    p2_files = [f for f in os.listdir(path_estimated_lds) if f.split(f\"_\")[6] == 'p2']\n",
    "    p2_files = sorted(p2_files, key=lambda x: int(x.split('_')[0]))\n",
    "    \n",
    "    twopq_files = [f for f in os.listdir(path_estimated_lds) if f.split(f\"_\")[6] == '2pq']\n",
    "    twopq_files = sorted(twopq_files, key=lambda x: int(x.split('_')[0]))\n",
    "    \n",
    "    \n",
    "    q2s = []\n",
    "    for q2_file in q2_files:\n",
    "        path_q2_file = path_estimated_lds + '/' + q2_file\n",
    "        q2 = pd.read_pickle(path_q2_file)\n",
    "        q2s.append(q2)\n",
    "    \n",
    "    q2s = pd.concat(q2s, axis=1)\n",
    "    q2s = q2s[list(complete.columns)]\n",
    "    q2s_pop.append(q2s)\n",
    "\n",
    "    p2s = []\n",
    "    for p2_file in p2_files:\n",
    "        path_p2_file = path_estimated_lds + '/' + p2_file\n",
    "        p2 = pd.read_pickle(path_p2_file)\n",
    "        p2s.append(p2)\n",
    "\n",
    "    p2s = pd.concat(p2s, axis=1)\n",
    "    p2s = p2s[list(complete.columns)]\n",
    "    p2s_pop.append(p2s)\n",
    "\n",
    "    \n",
    "    twopqs = []\n",
    "    for twopq_file in twopq_files:\n",
    "        path_2pq_file = path_estimated_lds + '/' + twopq_file\n",
    "        twopq = pd.read_pickle(path_2pq_file)\n",
    "        twopqs.append(twopq)\n",
    "\n",
    "    twopqs = pd.concat(twopqs, axis=1)\n",
    "    twopqs = twopqs[list(complete.columns)]\n",
    "    twopqs_pop.append(twopqs)\n",
    "\n",
    "\n",
    "q2s = pd.concat(q2s_pop, axis=0)\n",
    "q2s = q2s.sort_index()\n",
    "\n",
    "p2s = pd.concat(p2s_pop, axis=0)\n",
    "p2s = q2s.sort_index()\n",
    "\n",
    "twopqs = pd.concat(twopqs_pop, axis=0)\n",
    "twopqs = twopqs.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163bb68c-426d-4b3c-9af2-3220ea64d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2s + p2s + twopqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dace660-0a4a-4947-927b-487bf348fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1eb41-6a62-4843-b214-6c33a6be9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"rm -rf {path_output}/estimated_q2s_via_esti_pop.pkl\")\n",
    "os.system(f\"rm -rf {path_output}/estimated_p2s_via_esti_pop.pkl\")\n",
    "os.system(f\"rm -rf {path_output}/estimated_2pqs_via_esti_pop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda74497-ef4a-42b7-98e5-8eae1ba23c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2s.to_pickle(f\"{path_output}/estimated_q2s_via_esti_pop.pkl\")\n",
    "p2s.to_pickle(f\"{path_output}/estimated_p2s_via_esti_pop.pkl\")\n",
    "twopqs.to_pickle(f\"{path_output}/estimated_2pqs_via_esti_pop.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
