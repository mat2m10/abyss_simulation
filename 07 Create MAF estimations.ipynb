{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46e3528-f435-4c07-92e9-b74c5f062df9",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6528f9ad-fbc6-4822-8965-d5e70ce3156b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 13:05:33.197489: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-28 13:05:33.204047: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-28 13:05:33.219946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-28 13:05:33.251626: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-28 13:05:33.251713: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-28 13:05:33.274941: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-28 13:05:35.655064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from helpers import parse_variables, get_risk_level, hi_gauss_blob_risk_fun, blob_risk_fun, NW_risk_fun, square_risk_fun, map_to_color\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import importlib.util\n",
    "from k_means_constrained import KMeansConstrained\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "\n",
    "from helpers import parse_variables, get_risk_level, map_to_color, simulate_quant_trait\n",
    "from models import ols_regression, manhattan_linear, gc\n",
    "from deep_learning_models import abyss, deep_abyss\n",
    "\n",
    "from scipy.stats import t\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Input, Model, layers, regularizers\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487575fc-b220-49b6-9ef8-d1b027620a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = parse_variables('geno_simulation.txt')\n",
    "G = int(dict['G'])\n",
    "L = int(dict['L'])\n",
    "c = int(dict['c'])\n",
    "k = int(dict['k'])\n",
    "M = float(dict['M'])\n",
    "HWE = int(dict['HWE'])\n",
    "\n",
    "nr_humans = int(dict['nr_humans'])\n",
    "nr_snps = int(dict['nr_snps'])\n",
    "bottleneck_nr = int(dict['bottleneck_nr'])\n",
    "\n",
    "# Thresholds\n",
    "very_rare_threshold_L = float(dict['very_rare_threshold_L'])\n",
    "very_rare_threshold_H = float(dict['very_rare_threshold_H'])\n",
    "\n",
    "rare_threshold_L = float(dict['rare_threshold_L'])\n",
    "rare_threshold_H = float(dict['rare_threshold_H'])\n",
    "\n",
    "common_threshold_L = float(dict['common_threshold_L'])\n",
    "common_threshold_H = float(dict['common_threshold_H'])\n",
    "\n",
    "number_of_snps = (G*L)/2 # one loci per chromosome\n",
    "number_of_individuals = c*k*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c80e4e39-c78b-4e06-8948-1665faef4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_veryrare_genotype_AF_{very_rare_threshold_L}_{very_rare_threshold_H}.pkl\")\n",
    "rare = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_rare_genotype_AF_{rare_threshold_L}_{rare_threshold_H}.pkl\")\n",
    "common = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_common_genotype_AF_{common_threshold_L}_{common_threshold_H}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd20320-65c5-4ba5-9770-8d6f9442e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare = very_rare.rename(columns=lambda x: 'VR' + x)/2\n",
    "rare = rare.rename(columns=lambda x: 'R' + x)/2\n",
    "common = common.rename(columns=lambda x: 'C' + x)/2\n",
    "complete = pd.concat([common, rare, very_rare], axis=1)\n",
    "complete = ((complete*2)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1333e206-7330-40b0-ae40-a52923e39e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abyss_bottleneck_64_77.663seconds.pkl'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottle_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00341f68-3941-44a6-9255-f72b53af0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bottle = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/phenotype/abyss_bottleneck\"\n",
    "bottle_file = [f for f in os.listdir(path_bottle) if int(f.split(\"_\")[2]) ==  bottleneck_nr][0]\n",
    "elapsed_time_bottleneck = float(bottle_file.split('_')[3].split('seconds')[0])\n",
    "bottle = pd.read_pickle(f\"{path_bottle}/{bottle_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8514a344-7f08-4727-8edb-ff0d42e3bbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "      <th>dim5</th>\n",
       "      <th>dim6</th>\n",
       "      <th>dim7</th>\n",
       "      <th>dim8</th>\n",
       "      <th>dim9</th>\n",
       "      <th>dim10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim56</th>\n",
       "      <th>dim57</th>\n",
       "      <th>dim58</th>\n",
       "      <th>dim59</th>\n",
       "      <th>dim60</th>\n",
       "      <th>dim61</th>\n",
       "      <th>dim62</th>\n",
       "      <th>dim63</th>\n",
       "      <th>dim64</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.247320</td>\n",
       "      <td>0.558759</td>\n",
       "      <td>0.160977</td>\n",
       "      <td>0.071021</td>\n",
       "      <td>0.275661</td>\n",
       "      <td>0.586227</td>\n",
       "      <td>0.132713</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.388084</td>\n",
       "      <td>0.185918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732892</td>\n",
       "      <td>0.081761</td>\n",
       "      <td>0.121670</td>\n",
       "      <td>0.042011</td>\n",
       "      <td>0.380503</td>\n",
       "      <td>0.055630</td>\n",
       "      <td>0.244014</td>\n",
       "      <td>0.363884</td>\n",
       "      <td>0.061893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209328</td>\n",
       "      <td>0.565148</td>\n",
       "      <td>0.142860</td>\n",
       "      <td>0.137045</td>\n",
       "      <td>0.270371</td>\n",
       "      <td>0.511784</td>\n",
       "      <td>0.089762</td>\n",
       "      <td>0.069028</td>\n",
       "      <td>0.421283</td>\n",
       "      <td>0.183521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691966</td>\n",
       "      <td>0.118586</td>\n",
       "      <td>0.081019</td>\n",
       "      <td>0.066986</td>\n",
       "      <td>0.361386</td>\n",
       "      <td>0.070954</td>\n",
       "      <td>0.285308</td>\n",
       "      <td>0.397945</td>\n",
       "      <td>0.085473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.251229</td>\n",
       "      <td>0.488425</td>\n",
       "      <td>0.144627</td>\n",
       "      <td>0.170955</td>\n",
       "      <td>0.267871</td>\n",
       "      <td>0.484362</td>\n",
       "      <td>0.115141</td>\n",
       "      <td>0.075896</td>\n",
       "      <td>0.442830</td>\n",
       "      <td>0.175069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705041</td>\n",
       "      <td>0.165929</td>\n",
       "      <td>0.109381</td>\n",
       "      <td>0.025480</td>\n",
       "      <td>0.347549</td>\n",
       "      <td>0.061252</td>\n",
       "      <td>0.314206</td>\n",
       "      <td>0.434111</td>\n",
       "      <td>0.121496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.213875</td>\n",
       "      <td>0.553388</td>\n",
       "      <td>0.099140</td>\n",
       "      <td>0.048397</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.526767</td>\n",
       "      <td>0.070804</td>\n",
       "      <td>0.061034</td>\n",
       "      <td>0.473475</td>\n",
       "      <td>0.148031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829637</td>\n",
       "      <td>0.121872</td>\n",
       "      <td>0.061557</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.425308</td>\n",
       "      <td>0.048374</td>\n",
       "      <td>0.268701</td>\n",
       "      <td>0.446401</td>\n",
       "      <td>0.069396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235143</td>\n",
       "      <td>0.513232</td>\n",
       "      <td>0.143646</td>\n",
       "      <td>0.123940</td>\n",
       "      <td>0.270662</td>\n",
       "      <td>0.521322</td>\n",
       "      <td>0.119588</td>\n",
       "      <td>0.082772</td>\n",
       "      <td>0.425415</td>\n",
       "      <td>0.178843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736520</td>\n",
       "      <td>0.134714</td>\n",
       "      <td>0.111598</td>\n",
       "      <td>0.026647</td>\n",
       "      <td>0.376465</td>\n",
       "      <td>0.068374</td>\n",
       "      <td>0.287013</td>\n",
       "      <td>0.417703</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>0.280419</td>\n",
       "      <td>0.251336</td>\n",
       "      <td>0.474595</td>\n",
       "      <td>0.161040</td>\n",
       "      <td>0.481268</td>\n",
       "      <td>0.700591</td>\n",
       "      <td>0.164930</td>\n",
       "      <td>0.456915</td>\n",
       "      <td>0.405494</td>\n",
       "      <td>0.193323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159023</td>\n",
       "      <td>0.183242</td>\n",
       "      <td>0.117168</td>\n",
       "      <td>0.507177</td>\n",
       "      <td>0.427534</td>\n",
       "      <td>0.392159</td>\n",
       "      <td>0.696687</td>\n",
       "      <td>0.123606</td>\n",
       "      <td>0.104331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.258084</td>\n",
       "      <td>0.273270</td>\n",
       "      <td>0.430764</td>\n",
       "      <td>0.172704</td>\n",
       "      <td>0.486466</td>\n",
       "      <td>0.661814</td>\n",
       "      <td>0.118411</td>\n",
       "      <td>0.469123</td>\n",
       "      <td>0.403519</td>\n",
       "      <td>0.188910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182314</td>\n",
       "      <td>0.204074</td>\n",
       "      <td>0.088481</td>\n",
       "      <td>0.497135</td>\n",
       "      <td>0.439936</td>\n",
       "      <td>0.379171</td>\n",
       "      <td>0.701129</td>\n",
       "      <td>0.115604</td>\n",
       "      <td>0.092330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.323858</td>\n",
       "      <td>0.248029</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>0.209108</td>\n",
       "      <td>0.498652</td>\n",
       "      <td>0.672147</td>\n",
       "      <td>0.142135</td>\n",
       "      <td>0.422136</td>\n",
       "      <td>0.396271</td>\n",
       "      <td>0.177328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151385</td>\n",
       "      <td>0.242962</td>\n",
       "      <td>0.100492</td>\n",
       "      <td>0.476889</td>\n",
       "      <td>0.394025</td>\n",
       "      <td>0.340653</td>\n",
       "      <td>0.700534</td>\n",
       "      <td>0.105706</td>\n",
       "      <td>0.120453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.250809</td>\n",
       "      <td>0.316161</td>\n",
       "      <td>0.414623</td>\n",
       "      <td>0.137480</td>\n",
       "      <td>0.407878</td>\n",
       "      <td>0.637892</td>\n",
       "      <td>0.140013</td>\n",
       "      <td>0.420557</td>\n",
       "      <td>0.366142</td>\n",
       "      <td>0.204251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205633</td>\n",
       "      <td>0.223868</td>\n",
       "      <td>0.086058</td>\n",
       "      <td>0.463140</td>\n",
       "      <td>0.397854</td>\n",
       "      <td>0.369307</td>\n",
       "      <td>0.661276</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.092324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.230613</td>\n",
       "      <td>0.282717</td>\n",
       "      <td>0.489077</td>\n",
       "      <td>0.166502</td>\n",
       "      <td>0.567240</td>\n",
       "      <td>0.714617</td>\n",
       "      <td>0.072943</td>\n",
       "      <td>0.491566</td>\n",
       "      <td>0.522991</td>\n",
       "      <td>0.217105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201433</td>\n",
       "      <td>0.098664</td>\n",
       "      <td>0.092645</td>\n",
       "      <td>0.545336</td>\n",
       "      <td>0.509953</td>\n",
       "      <td>0.422243</td>\n",
       "      <td>0.712192</td>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.101037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dim1      dim2      dim3      dim4      dim5      dim6      dim7  \\\n",
       "0    0.247320  0.558759  0.160977  0.071021  0.275661  0.586227  0.132713   \n",
       "1    0.209328  0.565148  0.142860  0.137045  0.270371  0.511784  0.089762   \n",
       "2    0.251229  0.488425  0.144627  0.170955  0.267871  0.484362  0.115141   \n",
       "3    0.213875  0.553388  0.099140  0.048397  0.300691  0.526767  0.070804   \n",
       "4    0.235143  0.513232  0.143646  0.123940  0.270662  0.521322  0.119588   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "795  0.280419  0.251336  0.474595  0.161040  0.481268  0.700591  0.164930   \n",
       "796  0.258084  0.273270  0.430764  0.172704  0.486466  0.661814  0.118411   \n",
       "797  0.323858  0.248029  0.432062  0.209108  0.498652  0.672147  0.142135   \n",
       "798  0.250809  0.316161  0.414623  0.137480  0.407878  0.637892  0.140013   \n",
       "799  0.230613  0.282717  0.489077  0.166502  0.567240  0.714617  0.072943   \n",
       "\n",
       "         dim8      dim9     dim10  ...     dim56     dim57     dim58  \\\n",
       "0    0.050002  0.388084  0.185918  ...  0.732892  0.081761  0.121670   \n",
       "1    0.069028  0.421283  0.183521  ...  0.691966  0.118586  0.081019   \n",
       "2    0.075896  0.442830  0.175069  ...  0.705041  0.165929  0.109381   \n",
       "3    0.061034  0.473475  0.148031  ...  0.829637  0.121872  0.061557   \n",
       "4    0.082772  0.425415  0.178843  ...  0.736520  0.134714  0.111598   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "795  0.456915  0.405494  0.193323  ...  0.159023  0.183242  0.117168   \n",
       "796  0.469123  0.403519  0.188910  ...  0.182314  0.204074  0.088481   \n",
       "797  0.422136  0.396271  0.177328  ...  0.151385  0.242962  0.100492   \n",
       "798  0.420557  0.366142  0.204251  ...  0.205633  0.223868  0.086058   \n",
       "799  0.491566  0.522991  0.217105  ...  0.201433  0.098664  0.092645   \n",
       "\n",
       "        dim59     dim60     dim61     dim62     dim63     dim64  cluster  \n",
       "0    0.042011  0.380503  0.055630  0.244014  0.363884  0.061893        0  \n",
       "1    0.066986  0.361386  0.070954  0.285308  0.397945  0.085473        0  \n",
       "2    0.025480  0.347549  0.061252  0.314206  0.434111  0.121496        0  \n",
       "3    0.005857  0.425308  0.048374  0.268701  0.446401  0.069396        0  \n",
       "4    0.026647  0.376465  0.068374  0.287013  0.417703  0.096154        0  \n",
       "..        ...       ...       ...       ...       ...       ...      ...  \n",
       "795  0.507177  0.427534  0.392159  0.696687  0.123606  0.104331        0  \n",
       "796  0.497135  0.439936  0.379171  0.701129  0.115604  0.092330        0  \n",
       "797  0.476889  0.394025  0.340653  0.700534  0.105706  0.120453        0  \n",
       "798  0.463140  0.397854  0.369307  0.661276  0.142000  0.092324        0  \n",
       "799  0.545336  0.509953  0.422243  0.712192  0.169746  0.101037        0  \n",
       "\n",
       "[800 rows x 65 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad6f275c-51c4-4a1d-aae8-d0fb98c76c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fb470fa-be9d-49d5-b0cd-facb535506a5",
   "metadata": {},
   "source": [
    "# Run Abyss on LD block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6dc24c5-995c-48d5-859d-b35e04382eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maf_prediction(bottle_in, geno_out, epoch, patience):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(bottle_in, geno_out, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Regularization parameter\n",
    "    l2_regularizer = 0.001\n",
    "    \n",
    "    # Original autoencoder model with L2 regularization\n",
    "    decoder = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(int(nr_snps/2), activation='elu', input_shape=(bottle_in.shape[1],), kernel_regularizer=regularizers.l2(l2_regularizer)),  # First hidden layer with L2 regularization\n",
    "        layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('elu'),\n",
    "        tf.keras.layers.Dense(geno_out.shape[1], activation='linear', kernel_regularizer=regularizers.l2(l2_regularizer))  # Output layer\n",
    "    ])\n",
    "    \n",
    "    # Compile the original model with L2 regularization\n",
    "    decoder.compile(optimizer='adam',\n",
    "                        loss='mean_squared_error',\n",
    "                        metrics=['mean_absolute_error'])\n",
    "    \n",
    "    # Define Early Stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    \n",
    "    # Fit the original model with Early Stopping\n",
    "    history = decoder.fit(X_train, y_train, epochs=epoch, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    return decoder, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91492263-9f4d-4c05-9c6e-aa35ce0304ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pop in bottle['cluster'].unique():\n",
    "    temp_bottle = bottle[bottle['cluster'] == pop]\n",
    "    temp_bottle = temp_bottle.drop('cluster', axis=1)\n",
    "    path_output = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}/genotype/LD_blocks_estimated_mafs/{pop}\"\n",
    "    os.system(f\"rm -rf {path_output}\")\n",
    "    os.makedirs(path_output, exist_ok = True)\n",
    "    path_one_hot_genotype = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/LD_blocks_one_hot/{pop}\"\n",
    "    path_lds = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/LD_blocks/{pop}\"\n",
    "    ld_files = os.listdir(path_lds)\n",
    "    epoch = 200\n",
    "    patience = 15\n",
    "    p2s = []\n",
    "    twopqs = []\n",
    "    q2s = []\n",
    "\n",
    "    for ld_file in ld_files:\n",
    "        db_minor = pd.read_pickle(f\"{path_one_hot_genotype}/{ld_file.split('.pkl')[0]}_db_minor.pkl\")\n",
    "        db_het = pd.read_pickle(f\"{path_one_hot_genotype}/{ld_file.split('.pkl')[0]}_db_het.pkl\")\n",
    "        db_major = pd.read_pickle(f\"{path_one_hot_genotype}/{ld_file.split('.pkl')[0]}_db_major.pkl\")\n",
    "        \n",
    "        decoder, history = maf_prediction(temp_bottle, db_major, epoch, patience)\n",
    "        p2 = decoder(tf.convert_to_tensor(temp_bottle, dtype=tf.float32))\n",
    "        p2 = pd.DataFrame(data=p2, columns = db_major.columns)\n",
    "    \n",
    "        p2.index = db_major.index\n",
    "        p2s.append(p2)\n",
    "    \n",
    "        decoder, history = maf_prediction(temp_bottle, db_het, epoch, patience)\n",
    "        twopq = decoder(tf.convert_to_tensor(temp_bottle, dtype=tf.float32))\n",
    "        twopq = pd.DataFrame(data=twopq, columns = db_het.columns)\n",
    "        \n",
    "        twopq.index = db_het.index\n",
    "        twopqs.append(twopq)\n",
    "    \n",
    "        decoder, history = maf_prediction(temp_bottle, db_minor, epoch, patience)\n",
    "        q2 = decoder(tf.convert_to_tensor(temp_bottle, dtype=tf.float32))\n",
    "        q2 = pd.DataFrame(data=q2, columns = db_minor.columns)\n",
    "        \n",
    "        q2.index = db_minor.index\n",
    "        q2s.append(q2)\n",
    "        print(\"TOP\")\n",
    "\n",
    "    path_output_global = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/maf_pred/{pop}\"\n",
    "    p2 = pd.concat(p2s, axis=1)\n",
    "    p2 = p2.sort_index()\n",
    "    p2 = p2[list(complete.columns)]\n",
    "    \n",
    "    p2.to_pickle(f\"{path_output_global}/esti_p2_via_esti_pop.pkl\")\n",
    "\n",
    "    q2 = pd.concat(q2s, axis=1)\n",
    "    q2 = q2.sort_index()\n",
    "    q2 = q2[list(complete.columns)]\n",
    "    q2.to_pickle(f\"{path_output_global}/esti_q2_via_esti_pop.pkl\")\n",
    "\n",
    "\n",
    "    twopq = pd.concat(twopqs, axis=1)\n",
    "    twopq = twopq.sort_index()\n",
    "    twopq = twopq[list(complete.columns)]\n",
    "    twopq.to_pickle(f\"{path_output_global}/esti_2pq_via_esti_pop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c1ef5cc-3417-4578-8e4f-823624c60869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decfe955-a11e-4c6f-a52c-a40a5c289963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3362dc25-da78-4585-8b16-fe49f64ddc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588e47d-0a6c-4e94-bc44-4a945c77513d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da31282a-d70c-416e-9ade-71611df1071b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e95caff3-360b-45fe-b0b3-3cf843e31c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a02ca88-8784-4d4c-ae9a-6c948b95521c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccc7d6-6329-436e-a5db-8b7027738197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74111670-7666-4d58-8cb9-e6903aa5266e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be0d328-e6dd-4a05-bb7e-843bd1607c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
