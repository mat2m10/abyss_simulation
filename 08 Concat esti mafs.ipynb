{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bae6b1-e426-4c39-8efa-ff56244f78ba",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fcd8df6-7319-4f11-ab41-d7057646f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from helpers import parse_variables\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b83405-35b8-452f-ba88-f957b71fa89b",
   "metadata": {},
   "source": [
    "# Load simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76388184-438d-41c0-a770-c343d1a79b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = parse_variables('geno_simulation.txt')\n",
    "G = int(dict['G'])\n",
    "L = int(dict['L'])\n",
    "c = int(dict['c'])\n",
    "if 'k' not in globals():\n",
    "    k = int(dict['k'])\n",
    "    \n",
    "if 'M' not in globals():\n",
    "    M = float(dict['M'])\n",
    "HWE = int(dict['HWE'])\n",
    "\n",
    "nr_humans = int(dict['nr_humans'])\n",
    "nr_snps = int(dict['nr_snps'])\n",
    "bottleneck_nr = int(dict['bottleneck_nr'])\n",
    "\n",
    "if 'tools' not in globals():\n",
    "    tools = ['PCA', 'abyss_counted', 'abyss', 'no_corr']\n",
    "\n",
    "\n",
    "if 'scenarios' not in globals():\n",
    "    scenarios = ['snp_effect',\n",
    "                 'linear_continuous',\n",
    "                 'non_linear_continuous',\n",
    "                 'discrete_global',\n",
    "                 'discrete_localized',\n",
    "                 'mix_linear_continuous',\n",
    "                 'mix_non_linear_continuous',\n",
    "                 'mix_discrete_global',\n",
    "                 'mix_discrete_localized']\n",
    "\n",
    "if 'very_rare_threshold_L' not in globals():\n",
    "    very_rare_threshold_L = float(dict['very_rare_threshold_L'])\n",
    "if 'very_rare_threshold_H' not in globals():\n",
    "    very_rare_threshold_H = float(dict['very_rare_threshold_H'])\n",
    "if 'rare_threshold_L' not in globals():\n",
    "    rare_threshold_L = float(dict['rare_threshold_L'])\n",
    "if 'rare_threshold_H' not in globals():\n",
    "    rare_threshold_H = float(dict['rare_threshold_H'])\n",
    "if 'common_threshold_L' not in globals():\n",
    "    common_threshold_L = float(dict['common_threshold_L'])\n",
    "if 'common_threshold_H' not in globals():\n",
    "    common_threshold_H = float(dict['common_threshold_H'])\n",
    "\n",
    "number_of_snps = (G*L)/2 # one loci per chromosome\n",
    "number_of_individuals = c*k*k\n",
    "\n",
    "very_rare = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_veryrare_genotype_AF_{very_rare_threshold_L}_{very_rare_threshold_H}.pkl\")\n",
    "rare = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_rare_genotype_AF_{rare_threshold_L}_{rare_threshold_H}.pkl\")\n",
    "common = pd.read_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_common_genotype_AF_{common_threshold_L}_{common_threshold_H}.pkl\")\n",
    "\n",
    "complete = pd.concat([common, rare, very_rare], axis=1)\n",
    "complete = ((complete*2)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e2eb54-c4b4-45e4-b7b5-52ed1ad18ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'abyss' in tools:\n",
    "    path_bottle = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/phenotype/abyss_bottleneck\"\n",
    "    bottle_file = [f for f in os.listdir(path_bottle) if int(f.split(\"_\")[2]) ==  bottleneck_nr][0]\n",
    "    elapsed_time_bottleneck = float(bottle_file.split('_')[3].split('seconds')[0])\n",
    "    bottle = pd.read_pickle(f\"{path_bottle}/{bottle_file}\")\n",
    "\n",
    "    path_pops_estimated_lds = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/LD_blocks_estimated_mafs/\"\n",
    "\n",
    "\n",
    "    q2s_pop = []\n",
    "    twopqs_pop = []\n",
    "    p2s_pop = []\n",
    "    \n",
    "    time_q2 = 0.0\n",
    "    time_p2 = 0.0\n",
    "    time_2pq = 0.0\n",
    "    \n",
    "    for pop in os.listdir(path_pops_estimated_lds):\n",
    "        bottle_index = bottle[bottle['cluster']==int(pop)]\n",
    "        path_estimated_lds = path_pops_estimated_lds + \"/\" + pop\n",
    "        q2_files = [f for f in os.listdir(path_estimated_lds) if f.split(f\"_\")[6] == 'q2']\n",
    "        q2_files = sorted(q2_files, key=lambda x: int(x.split('_')[0]))\n",
    "        p2_files = [f for f in os.listdir(path_estimated_lds) if f.split(f\"_\")[6] == 'p2']\n",
    "        p2_files = sorted(p2_files, key=lambda x: int(x.split('_')[0]))\n",
    "        \n",
    "        twopq_files = [f for f in os.listdir(path_estimated_lds) if f.split(f\"_\")[6] == '2pq']\n",
    "        twopq_files = sorted(twopq_files, key=lambda x: int(x.split('_')[0]))\n",
    "        \n",
    "        \n",
    "        q2s = []\n",
    "        for q2_file in q2_files:\n",
    "            time_q2 += float(q2_file.split('_pop_')[1].split(\"seconds\")[0])\n",
    "            path_q2_file = path_estimated_lds + '/' + q2_file\n",
    "            q2 = pd.read_pickle(path_q2_file)\n",
    "            q2s.append(q2)\n",
    "        \n",
    "        q2s = pd.concat(q2s, axis=1)\n",
    "        q2s = q2s[list(complete.columns)]\n",
    "        q2s_pop.append(q2s)\n",
    "    \n",
    "        p2s = []\n",
    "        for p2_file in p2_files:\n",
    "            time_p2 += float(p2_file.split('_pop_')[1].split(\"seconds\")[0])\n",
    "    \n",
    "            path_p2_file = path_estimated_lds + '/' + p2_file\n",
    "            p2 = pd.read_pickle(path_p2_file)\n",
    "            p2s.append(p2)\n",
    "    \n",
    "        p2s = pd.concat(p2s, axis=1)\n",
    "        p2s = p2s[list(complete.columns)]\n",
    "        p2s_pop.append(p2s)\n",
    "    \n",
    "        \n",
    "        twopqs = []\n",
    "        for twopq_file in twopq_files:\n",
    "            time_2pq += float(twopq_file.split('_pop_')[1].split(\"seconds\")[0])\n",
    "            path_2pq_file = path_estimated_lds + '/' + twopq_file\n",
    "            twopq = pd.read_pickle(path_2pq_file)\n",
    "            twopqs.append(twopq)\n",
    "    \n",
    "        twopqs = pd.concat(twopqs, axis=1)\n",
    "        twopqs = twopqs[list(complete.columns)]\n",
    "        twopqs_pop.append(twopqs)\n",
    "    \n",
    "    \n",
    "    q2s = pd.concat(q2s_pop, axis=0)\n",
    "    q2s = q2s.sort_index()\n",
    "    \n",
    "    p2s = pd.concat(p2s_pop, axis=0)\n",
    "    p2s = p2s.sort_index()\n",
    "    \n",
    "    twopqs = pd.concat(twopqs_pop, axis=0)\n",
    "    twopqs = twopqs.sort_index()\n",
    "\n",
    "    path_output = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/\"\n",
    "    os.system(f\"rm -rf {path_output}/estimated*\")\n",
    "    q2s.to_pickle(f\"{path_output}/estimated_q2s_via_esti_pop_{time_q2}seconds.pkl\")\n",
    "    p2s.to_pickle(f\"{path_output}/estimated_p2s_via_esti_pop_{time_p2}seconds.pkl\")\n",
    "    twopqs.to_pickle(f\"{path_output}/estimated_2pqs_via_esti_pop_{time_2pq}seconds.pkl\")\n",
    "\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221544fd-1148-4227-88a9-048793069bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66fe067-eced-4d6a-b7c8-e850f4993989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
