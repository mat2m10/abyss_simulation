{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3f0af-615b-4077-82a4-6bbbc757f440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 11:10:55.181344: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-24 11:10:55.264165: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-24 11:10:55.264254: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-24 11:10:55.272890: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-24 11:10:55.308448: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-24 11:10:55.309731: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-24 11:10:56.397643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import importlib.util\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import regularizers\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Input, layers, Model, regularizers, callbacks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, layers, regularizers\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# Add the parent directory to the module search path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Import functions from helpers module\n",
    "from helpers import parse_variables, get_risk_level, map_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfeb41-8ee0-4c1d-96bc-6c5dae9ae390",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = parse_variables('../geno_simulation.txt')\n",
    "G = int(dict['G'])\n",
    "L = int(dict['L'])\n",
    "c = int(dict['c'])\n",
    "k = int(dict['k'])\n",
    "M = float(dict['M'])\n",
    "\n",
    "# Thresholds\n",
    "very_rare_threshold_L = float(dict['very_rare_threshold_L'])\n",
    "very_rare_threshold_H = float(dict['very_rare_threshold_H'])\n",
    "\n",
    "rare_threshold_L = float(dict['rare_threshold_L'])\n",
    "rare_threshold_H = float(dict['rare_threshold_H'])\n",
    "\n",
    "common_threshold_L = float(dict['common_threshold_L'])\n",
    "common_threshold_H = float(dict['common_threshold_H'])\n",
    "\n",
    "path_risk=\"../pheno_simulation.txt\"\n",
    "risk_level = get_risk_level(path_risk)\n",
    "risk_level = risk_level.split(\"\\n\")[-1]\n",
    "\n",
    "# Define the module name and file path\n",
    "module_name = 'helpers'\n",
    "module_file_path = '../helpers.py'  # Replace '../path/to/helpers.py' with the actual path to helpers.py\n",
    "\n",
    "# Load the module dynamically\n",
    "module_spec = importlib.util.spec_from_file_location(module_name, module_file_path)\n",
    "helpers = importlib.util.module_from_spec(module_spec)\n",
    "module_spec.loader.exec_module(helpers)\n",
    "# Get the function dynamically\n",
    "risk_function = getattr(helpers, risk_level)\n",
    "\n",
    "name_risk = risk_level.split('_fun')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ac070-8e40-4df8-b101-ef7317623a69",
   "metadata": {},
   "source": [
    "# Load populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71457e6-2b18-4ed9-bd9f-e3009a5a542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = pd.read_pickle(f\"../data/phenotype/simulated_population_G{G}_L{L}_c{c}_k{k}_M{M}.pkl\")\n",
    "palette = [map_to_color(x, y, z, populations) for x, y, z in zip(populations['x'], populations['y'], populations['z'])]\n",
    "populations['population'] = populations['populations'].str.extract('(\\d+)').astype(int)\n",
    "populations[\"population_number\"] = populations['population']/populations['population'].max()\n",
    "# Check the grid\n",
    "df_agg = populations.groupby(['x', 'y']).agg({'population': 'mean'}).reset_index()\n",
    "\n",
    "# Now, pivot the aggregated DataFrame\n",
    "grid_df = df_agg.pivot(index='y', columns='x', values='population')\n",
    "\n",
    "# Use seaborn to create the heatmap\n",
    "plt.figure(figsize=(10, 10))\n",
    "heatmap = sns.heatmap(grid_df, cmap=palette, linewidths=.5, square=True, cbar=False)\n",
    "\n",
    "# Add a title to the heatmap\n",
    "plt.title('Population Grid', fontsize=16)\n",
    "plt.gca().invert_yaxis()  # Sometimes it's necessary to invert the y-axis for correct orientation\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ccff1-db4f-4192-82eb-e6777cad1508",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c544c-e67c-4ae0-ada0-39f5635c7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno = pd.read_pickle(f\"../data/genotype/simulated_complete_genotypes_AF_0_0.5_G{G}_L{L}_c{c}_k{k}_M{M}.pkl\")\n",
    "AFs = pd.read_pickle(f\"../data/genotype/simulated_complete_frequencies_AF_0_0.5_G{G}_L{L}_c{c}_k{k}_M{M}.pkl\")\n",
    "pheno = pd.read_pickle(f\"../data/phenotype/simulatedcase_control_onlyenvrisk_{name_risk}_G{G}_L{L}_c{c}_k{k}_M{M}.pkl\")\n",
    "name_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f354f9a-1dbd-43e7-b98b-86a7f35adcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1190d-2739-4359-afaf-1f81bb8ef2b6",
   "metadata": {},
   "source": [
    "# Step by step AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad8b686-286b-45b8-b665-b13d780c1073",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a454e-166a-4d7f-a4e3-c11e9329b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = pheno[['case_control_env']]\n",
    "#for snp in list(geno.columns):\n",
    "#    temp[snp] = list(pheno['case_control_env'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f574016-1cc8-402e-b1d1-99d11c1465a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = temp[list(geno.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9cd419-9aca-4516-bf1a-ffde3445e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno  = geno-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec8ba8-860f-4234-ac87-7210858e40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df6b5b-8bef-47d4-afc7-a220c4de1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, layers, Model, regularizers\n",
    "\n",
    "# Assuming you have defined geno and pheno data\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, pheno_train, pheno_test = train_test_split(geno, geno, pheno[['case_control_env']], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define your regularization strength (lambda)\n",
    "l2_lambda = 0.001  # Adjust this value as needed\n",
    "\n",
    "# Define input layers\n",
    "input_shape_geno = geno.shape[1:]\n",
    "input_layer_geno = Input(shape=input_shape_geno, name='input_geno')\n",
    "\n",
    "input_shape_pheno = pheno.shape[1:]\n",
    "input_layer_pheno = Input(shape=input_shape_pheno, name='input_pheno')\n",
    "\n",
    "# Define bottleneck size\n",
    "bottle = 15\n",
    "size_layer_1 = int(round(input_shape_geno[0]) / 2)\n",
    "\n",
    "# Create layers\n",
    "encoder_init_1 = layers.Dense(bottle, \n",
    "                       activation=\"elu\", \n",
    "                       name=\"encoder_init_1\",\n",
    "                       kernel_regularizer=regularizers.l2(l2_lambda))\n",
    "\n",
    "decoder_init_2 = layers.Dense(input_shape_geno[0], \n",
    "                       activation=\"elu\", \n",
    "                       name=\"decoder_init_2\",\n",
    "                       kernel_regularizer=regularizers.l2(l2_lambda))\n",
    "\n",
    "predictor = layers.Dense(input_shape_pheno[0], \n",
    "                       activation=\"linear\", \n",
    "                       name=\"predictor\",\n",
    "                       kernel_regularizer=regularizers.l2(l2_lambda))\n",
    "\n",
    "# Define custom layer for element-wise trainable weights\n",
    "class ElementWiseWeightsLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ElementWiseWeightsLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.weight = self.add_weight(shape=(), initializer=\"ones\", trainable=True, name=\"element_wise_weight\")\n",
    "        super(ElementWiseWeightsLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs * self.weight\n",
    "\n",
    "# Define encoder and decoder paths\n",
    "bottle_neck = encoder_init_1(input_layer_geno)\n",
    "allele_frequency_probability = decoder_init_2(bottle_neck)\n",
    "y = predictor(allele_frequency_probability)\n",
    "\n",
    "# Define the model\n",
    "autoencoder = Model(inputs=input_layer_geno, outputs=[allele_frequency_probability, y], name=\"fishy\")\n",
    "# Extract the bottleneck layer\n",
    "bottleneck_model = tf.keras.Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoder_init_1').output)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss=['mse', 'mse'], loss_weights=[1.0, 0.0])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = autoencoder.fit(X_train, [X_train, pheno_train], epochs=epochs, batch_size=32, validation_data=(X_test, [X_test, pheno_test]), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = autoencoder.evaluate(X_test, [y_test, pheno_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0532cf-143f-4dcd-8e7f-dcf129119eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957af37-b9bc-46d5-b0f7-6e2ebc610cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the bottleneck layer, allele frequency probability, and predicted y for a given input\n",
    "allele_frequency_output, y_output = autoencoder.predict(geno)\n",
    "\n",
    "# bottleneck_output contains the output of the bottleneck layer\n",
    "# allele_frequency_output contains the output of the allele frequency probability layer\n",
    "# y_output contains the predicted output y\n",
    "\n",
    "# If you want to inspect the shapes of these outputs:\n",
    "#print(\"Bottleneck output shape:\", bottleneck_output.shape)\n",
    "print(\"Allele frequency probability output shape:\", allele_frequency_output.shape)\n",
    "print(\"Predicted y output shape:\", y_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb681b8-cb72-412d-a6b6-e4f5c3a71f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first two hidden layers\n",
    "hidden_layer_1 = autoencoder.get_layer('encoder_init_1')\n",
    "#hidden_layer_2 = autoencoder.get_layer('encoder_init_2')\n",
    "# Define input layer\n",
    "input_layer = autoencoder.input\n",
    "\n",
    "# Define the output of the first hidden layer\n",
    "output_hidden_1 = hidden_layer_1(input_layer)\n",
    "\n",
    "# Define the output of the second hidden layer\n",
    "#output_hidden_2 = hidden_layer_2(output_hidden_1)\n",
    "\n",
    "# Create a new model with only the first two hidden layers\n",
    "new_model = tf.keras.Model(inputs=input_layer, outputs=output_hidden_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f72ea-cfb1-4689-9319-faeb3e816749",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle = new_model.predict(geno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa567b7d-7571-42a0-9e66-aa1b87c3f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(bottle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa91d36-567e-4a1c-a21f-4ae9db0d02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894af8a-6dd9-4a30-bce3-49b726447864",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3347e-776e-4c57-861b-f9c5b0cf9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81278440-dc2b-45da-8f22-b0ae0785de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_labels = [f\"dim{i}\" for i in range(1, bottle + 1)]\n",
    "\n",
    "bottle_df = pd.DataFrame(data=bottle, columns=dim_labels)\n",
    "to_have_collumns = ['populations','population_number', 'x', 'y','z','population']\n",
    "bottle_df[to_have_collumns] = populations[to_have_collumns]\n",
    "bottle_df['pheno'] = list(pheno[\"case_control_env\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da67d4c-5b50-498b-a248-7170547626bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Count the unique values in the 'populations' column\n",
    "unique_populations = bottle_df['populations'].nunique()\n",
    "\n",
    "# Plotting the principal components with colors\n",
    "colors = [map_to_color(x, y, z, bottle_df) for x, y, z in zip(bottle_df['x'], bottle_df['y'], bottle_df['z'])]\n",
    "plt.scatter(x=bottle_df['dim1'], y=bottle_df['dim2'], c=colors, s=40)\n",
    "\n",
    "plt.title('Complete Dataset')  # Set the title for the plot\n",
    "plt.xlabel('dim1 1')\n",
    "plt.ylabel('dim 2')\n",
    "\n",
    "# Only show the legend if there are 16 or fewer unique populations\n",
    "if unique_populations <= 16:\n",
    "    plt.legend(title='Population', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "else:\n",
    "    plt.legend([], [], frameon=False)  # This hides the legend\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c4b2c4-2223-49a1-9a7a-2e67582e9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plotting the principal components with colors based on 'pheno'\n",
    "sns.scatterplot(data=bottle_df, x='dim1', y='dim2', hue='pheno', s=40)\n",
    "\n",
    "plt.title('Complete Dataset')  # Set the title for the plot\n",
    "plt.xlabel('dim1')\n",
    "plt.ylabel('dim2')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314bce42-1870-47ee-8abb-d2faf843d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "probmaf = (pd.DataFrame(data=allele_frequency_output, columns = geno.columns)+1)/2\n",
    "probmaf = 1-probmaf\n",
    "probmaf.to_pickle(f\"../data/estimated p values/estimated_af_deep_G{G}_L{L}_c{c}_k{k}_M{M}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280d7dd-74da-4db7-b935-f42b17c93a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_AF = probmaf.mean(axis=0)\n",
    "sns.scatterplot(x=list(AFs['AFs']), y=list(estimated_AF))\n",
    "plt.xlabel('True Global Minor Allele Frequencies')\n",
    "plt.ylabel('Mean of Estimated Allele Frequencies')\n",
    "plt.title('Comparison of True and Estimated Allele Frequencies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b57c9-f728-4e49-ab55-89ae3ec48738",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1960f4-9717-47c9-80e6-fd4b3225247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno['predicted'] = list(pd.DataFrame(y_output).mean(axis=1))\n",
    "correlation = pheno['case_control_env'].corr(pheno['predicted'])\n",
    "print(\"Correlation between column1 and column2:\", correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b0a50-23c6-4c02-abf0-6a986c880e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7d3c8-623d-4b3f-aad2-0cda9124ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=list(pd.DataFrame(y_output).mean(axis=1)), y=list(pheno[name_risk]))\n",
    "plt.xlabel('True Global risk')\n",
    "plt.ylabel('Mean of Estimated risks')\n",
    "plt.title('Comparison of Estimated and true risk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f39c78-11e5-4b94-b303-671a874091d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a8633e-43d3-40f9-a321-ac10188780f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20dfc6-5793-4b9a-b63b-dd0a811329f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
