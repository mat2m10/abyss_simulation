{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c3d088-0fdf-4b71-bf4a-4e8a6ee8ffbc",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af9b1343-1bd5-409c-95a1-9fc962a6a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from helpers import parse_variables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from helpers import parse_variables\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0da7493-94f8-4f1a-8c93-82219ea8839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = parse_variables('geno_simulation.txt')\n",
    "if 'G' not in globals():\n",
    "    G = int(dict['G'])\n",
    "if 'L' not in globals():\n",
    "    L = int(dict['L'])\n",
    "if 'c' not in globals():\n",
    "    c = int(dict['c'])\n",
    "if 'k' not in globals():\n",
    "    k = int(dict['k'])\n",
    "if 'M' not in globals():\n",
    "    M = float(dict['M'])\n",
    "if 'HWE' not in globals():\n",
    "    HWE = int(dict['HWE'])\n",
    "\n",
    "if 'tools' not in globals():\n",
    "    tools = ['PCA', 'abyss_counted', 'abyss', 'no_corr']\n",
    "\n",
    "\n",
    "if 'scenarios' not in globals():\n",
    "    scenarios = ['snp_effect',\n",
    "                 'linear_continuous',\n",
    "                 'non_linear_continuous',\n",
    "                 'discrete_global',\n",
    "                 'discrete_localized',\n",
    "                 'mix_linear_continuous',\n",
    "                 'mix_non_linear_continuous',\n",
    "                 'mix_discrete_global',\n",
    "                 'mix_discrete_localized']\n",
    "\n",
    "if 'very_rare_threshold_L' not in globals():\n",
    "    very_rare_threshold_L = float(dict['very_rare_threshold_L'])\n",
    "if 'very_rare_threshold_H' not in globals():\n",
    "    very_rare_threshold_H = float(dict['very_rare_threshold_H'])\n",
    "if 'rare_threshold_L' not in globals():\n",
    "    rare_threshold_L = float(dict['rare_threshold_L'])\n",
    "if 'rare_threshold_H' not in globals():\n",
    "    rare_threshold_H = float(dict['rare_threshold_H'])\n",
    "if 'common_threshold_L' not in globals():\n",
    "    common_threshold_L = float(dict['common_threshold_L'])\n",
    "if 'common_threshold_H' not in globals():\n",
    "    common_threshold_H = float(dict['common_threshold_H'])\n",
    "\n",
    "# Define the R commands to run, passing parameters as arguments\n",
    "commands = [\n",
    "    f\"source('geno_simulation.txt')\",\n",
    "    f\"source('create_geno.R', echo=TRUE)\",\n",
    "]\n",
    "\n",
    "\n",
    "commands = [\n",
    "    \"source('geno_simulation.txt')\",\n",
    "    f\"G <- {G}\",\n",
    "    f\"L <- {L}\",\n",
    "    f\"c <- {c}\",\n",
    "    f\"k <- {k}\",\n",
    "    f\"M <- {M}\",\n",
    "    \"source('create_geno.R', echo=TRUE)\"\n",
    "]\n",
    "\n",
    "# Concatenate commands into a single string\n",
    "r_script = \";\".join(commands)\n",
    "\n",
    "# Run the R script\n",
    "result = subprocess.run(['Rscript', '-e', r_script], capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "#print(result.stdout)\n",
    "\n",
    "# Check for errors\n",
    "if result.returncode != 0:\n",
    "    print(\"Error executing R script:\")\n",
    "    print(result.stderr)\n",
    "    pass\n",
    "\n",
    "os.makedirs(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/raw\",exist_ok=True)\n",
    "os.system(f\"mv simulated_genotypes_G{G}_L{L}_c{c}_k{k}_M{M}.csv data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/raw/\")\n",
    "\n",
    "file = f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/raw/simulated_genotypes_G{G}_L{L}_c{c}_k{k}_M{M}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32cda3c3-3e77-490b-ae8e-ed26fbfb9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_simulated_file = \"./\"+ file\n",
    "number_of_loci = G*L\n",
    "number_of_individuals = c*k*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "490db2c8-ba73-416c-aa12-bb423cea9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_loci= pd.read_csv(path_simulated_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d861c6f7-d783-4015-ab33-51a2dce80408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pair SNPs and summarize genotype\n",
    "def summarize_genotypes(df):\n",
    "    summarized_genotypes = {}\n",
    "    # Iterate over pairs of columns\n",
    "    for i in range(1, df.shape[1], 2):\n",
    "        pair_sum = df.iloc[:, i-1] + df.iloc[:, i]\n",
    "        # Apply the genotype summarization logic\n",
    "        summarized_genotypes[f'G{i//2 + 1}'] = np.where(pair_sum == 2, 2, pair_sum)\n",
    "    return pd.DataFrame(summarized_genotypes)\n",
    "\n",
    "# Apply the function to the sample DataFrame\n",
    "simulated_genotype = summarize_genotypes(simulated_loci)\n",
    "columns_to_drop  = simulated_genotype.columns[simulated_genotype.nunique() == 1] # If double columns delete it \n",
    "simulated_genotype = simulated_genotype.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9fe302c-5b9b-4257-bedb-edf868ab9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_populations = k*k\n",
    "labels_pop = []\n",
    "for i in range(number_of_populations):\n",
    "    labels_pop += [i+1]*c\n",
    "\n",
    "simulated_genotype[\"populations\"] = labels_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "441388bb-ede4-4526-93a2-cffc462839cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pops = list(set(labels_pop))\n",
    "unique_pops.sort()\n",
    "dfs = []\n",
    "required_values = {0, 1, 2}\n",
    "\n",
    "# Optimization: Cache the set operation result\n",
    "simulated_genotype_sets = {col: set(simulated_genotype[col]) for col in simulated_genotype.columns}\n",
    "\n",
    "if HWE == 1:\n",
    "    for pop in unique_pops:\n",
    "        temp_pop = simulated_genotype[simulated_genotype[\"populations\"] == pop].drop('populations', axis=1)\n",
    "        \n",
    "        for col in temp_pop.columns:\n",
    "            column_values = simulated_genotype_sets[col]\n",
    "            \n",
    "            if not required_values.issubset(column_values):\n",
    "                # Optimization: Vectorized random choice and assignment\n",
    "                indices = np.random.choice(temp_pop.index, size=3, replace=False)\n",
    "                temp_pop.loc[indices[0], col] = 0\n",
    "                temp_pop.loc[indices[1], col] = 1\n",
    "                temp_pop.loc[indices[2], col] = 2\n",
    "\n",
    "            # Calculate frequencies\n",
    "            value_counts = temp_pop[col].value_counts().reindex([0, 1, 2], fill_value=0)\n",
    "            total = value_counts.sum()\n",
    "            q = (2*value_counts[2] + value_counts[1])/ (2*total)\n",
    "            if q > 0.5:\n",
    "                q = 1-q\n",
    "            p = 1 - q\n",
    "            freq_maj = p ** 2\n",
    "            freq_het = 2 * p * q\n",
    "            freq_min = q ** 2\n",
    "\n",
    "            # Optimization: Vectorized assignment of new genotypes\n",
    "            pop_geno = np.random.choice([1.0, 0.0, -1.0], size=total, p=[freq_maj, freq_het, freq_min])\n",
    "            temp_pop[col] = pop_geno\n",
    "\n",
    "        dfs.append(temp_pop)\n",
    "\n",
    "else:\n",
    "    print(\"HWE\")\n",
    "    for pop in unique_pops:\n",
    "        temp_pop = simulated_genotype[simulated_genotype[\"populations\"] == pop].drop('populations', axis=1)\n",
    "        \n",
    "        for col in temp_pop.columns:\n",
    "            column_values = simulated_genotype_sets[col]\n",
    "            \n",
    "            if not required_values.issubset(column_values):\n",
    "                # Optimization: Vectorized random choice and assignment\n",
    "                indices = np.random.choice(temp_pop.index, size=3, replace=False)\n",
    "                temp_pop.loc[indices[0], col] = 0\n",
    "                temp_pop.loc[indices[1], col] = 1\n",
    "                temp_pop.loc[indices[2], col] = 2\n",
    "\n",
    "            # Calculate frequencies\n",
    "            value_counts = temp_pop[col].value_counts().reindex([0, 1, 2], fill_value=0)\n",
    "            total = value_counts.sum()\n",
    "\n",
    "            q = (2*value_counts[2] + value_counts[1])/ (2*total)\n",
    "            if q > 0.5:\n",
    "                q = 1-q\n",
    "            p = 1 - q\n",
    "            freq_maj = p ** 2\n",
    "            freq_het = q ** 2\n",
    "            freq_min = 2 * p * q\n",
    "\n",
    "            # Optimization: Vectorized assignment of new genotypes\n",
    "            pop_geno = np.random.choice([1.0, 0.0, -1.0], size=total, p=[freq_maj, freq_het, freq_min])\n",
    "            temp_pop[col] = pop_geno\n",
    "\n",
    "        dfs.append(temp_pop)\n",
    "\n",
    "# Concatenate all dataframes if needed\n",
    "simulated_genotype = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45d6f505-8f3a-455a-8afb-241d2888bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_genotype = simulated_genotype + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7e94759-5d21-458c-84a3-3bdaa33abc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate when AF is > 0.5 and change the genotype\n",
    "# Initialize a dictionary to store allele frequencies\n",
    "allele_frequencies = {}\n",
    "\n",
    "# Calculate allele frequencies for each SNP column\n",
    "for snp in simulated_genotype.columns:\n",
    "    total_alleles = 2 * len(simulated_genotype[snp])  # Total number of alleles (2 alleles per sample)\n",
    "    minor_allele_count = (2 * simulated_genotype[snp].value_counts().get(0, 0)) + simulated_genotype[snp].value_counts().get(1, 0)\n",
    "    allele_frequency = minor_allele_count / total_alleles\n",
    "    allele_frequencies[snp] = allele_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "590377b0-e1d7-4e19-afde-ae7abe15ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = simulated_genotype.T\n",
    "temp['AFs'] = allele_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3428730d-9077-4fbe-a3a9-997808e51f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to flip 0s to 2s and 2s to 0s\n",
    "def flip_genotypes(row):\n",
    "    if row['AFs'] > 0.5:\n",
    "        # Apply transformation for the condition\n",
    "        row[:-1] = row[:-1].replace({0: 2, 2: 0})\n",
    "        row['AFs'] = 1 - row['AFs']  # Adjust allele frequency\n",
    "    return row\n",
    "\n",
    "# Apply the function across the DataFrame, row-wise\n",
    "df_transformed = temp.apply(flip_genotypes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cce63e7-26a4-4eca-9e7b-86304e7f0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_genotype = df_transformed.drop('AFs', axis=1).T\n",
    "columns_to_drop  = simulated_genotype.columns[simulated_genotype.nunique() == 1] # If double columns delete it \n",
    "simulated_genotype = simulated_genotype.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "814c0489-ac46-4eeb-be21-c20c6c40b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_all_genotypes(series, genotypes={0.0, 1.0, 2.0}):\n",
    "    return genotypes.issubset(series.unique())\n",
    "\n",
    "simulated_genotype = simulated_genotype[[col for col in simulated_genotype.columns if contains_all_genotypes(simulated_genotype[col])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d7aadb-f7c4-4b43-bab2-44ff42813088",
   "metadata": {},
   "source": [
    "# Recalculate AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a345a8cd-6f35-4c9e-a90b-e467dafc5156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate when AF is > 0.5 and change the genotype\n",
    "# Initialize a dictionary to store allele frequencies\n",
    "allele_frequencies = {}\n",
    "\n",
    "# Calculate allele frequencies for each SNP column\n",
    "for snp in simulated_genotype.columns:\n",
    "    total_alleles = 2 * len(simulated_genotype[snp])  # Total number of alleles (2 alleles per sample)\n",
    "    minor_allele_count = (2 * simulated_genotype[snp].value_counts().get(0, 0)) + simulated_genotype[snp].value_counts().get(1, 0)\n",
    "    allele_frequency = minor_allele_count / total_alleles\n",
    "    allele_frequencies[snp] = allele_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0de3424-ff06-45d0-91db-9d71f0d599a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = simulated_genotype.T\n",
    "temp['AFs'] = allele_frequencies\n",
    "AFs = temp[['AFs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c41efcbf-2a18-4f23-84f2-cb8af1a7deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create slices as copies to avoid SettingWithCopyWarning\n",
    "very_rare = temp[(temp['AFs'] > very_rare_threshold_L) & (temp['AFs'] <= very_rare_threshold_H)].copy()\n",
    "rare = temp[(temp['AFs'] > rare_threshold_L) & (temp['AFs'] <= rare_threshold_H)].copy()\n",
    "common = temp[(temp['AFs'] > common_threshold_L) & (temp['AFs'] <= common_threshold_H)].copy()\n",
    "\n",
    "# Modify 'snps' column using .loc to avoid warnings\n",
    "very_rare.loc[:, 'snps'] = very_rare.index + '_AF_' + very_rare['AFs'].astype(str)\n",
    "very_rare.set_index('snps', inplace=True)\n",
    "very_rare_to_save = very_rare.drop('AFs', axis=1).T\n",
    "very_rare_afs = very_rare[['AFs']]\n",
    "\n",
    "rare.loc[:, 'snps'] = rare.index + '_AF_' + rare['AFs'].astype(str)\n",
    "rare.set_index('snps', inplace=True)\n",
    "rare_to_save = rare.drop('AFs', axis=1).T\n",
    "rare_afs = rare[['AFs']]\n",
    "\n",
    "common.loc[:, 'snps'] = common.index + '_AF_' + common['AFs'].astype(str)\n",
    "common.set_index('snps', inplace=True)\n",
    "common_to_save = common.drop('AFs', axis=1).T\n",
    "common_afs = common[['AFs']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87a4b017-b706-41c7-9a63-4be300448316",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare_to_save = very_rare_to_save.rename(columns=lambda x: 'VR' + x)/2\n",
    "rare_to_save = rare_to_save.rename(columns=lambda x: 'R' + x)/2\n",
    "common_to_save = common_to_save.rename(columns=lambda x: 'C' + x)/2\n",
    "complete = pd.concat([common_to_save, rare_to_save, very_rare_to_save], axis=1)\n",
    "complete = ((complete*2)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e28fced-15fb-45b9-86e1-f544420f4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_rare_to_save.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_veryrare_genotype_AF_{very_rare_threshold_L}_{very_rare_threshold_H}.pkl\")\n",
    "rare_to_save.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_rare_genotype_AF_{rare_threshold_L}_{rare_threshold_H}.pkl\")\n",
    "common_to_save.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/01_common_genotype_AF_{common_threshold_L}_{common_threshold_H}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfa8effd-1e4e-4cf2-9676-da749327ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(f\"rm data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/02_true_p2_via_true_pop.pkl\")\n",
    "#os.system(f\"rm data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/02_true_twopq_via_true_pop.pkl\")\n",
    "#os.system(f\"rm data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/02_true_q2_via_true_pop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee516347-2f85-40d1-80eb-4565a562d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete['pop'] = labels_pop\n",
    "\n",
    "p2s_dfs = []\n",
    "q2s_dfs = []\n",
    "twopqs_dfs = []\n",
    "\n",
    "for pop in complete['pop'].unique():\n",
    "    temp = complete[complete['pop'] == pop].drop(\"pop\", axis=1)\n",
    "\n",
    "    # Count the number of major, heterozygous, and minor alleles\n",
    "    counts = temp.apply(pd.Series.value_counts).fillna(0)\n",
    "\n",
    "    num_maj = counts.loc[1.0]\n",
    "    num_het = counts.loc[0.0]\n",
    "    num_min = counts.loc[-1.0]\n",
    "\n",
    "    total_humans = num_maj + num_het + num_min\n",
    "\n",
    "    # Normalize to get frequencies instead of counts\n",
    "    p2s = num_maj / total_humans\n",
    "    twopqs = num_het / total_humans\n",
    "    q2s = num_min / total_humans\n",
    "\n",
    "    # Expand the normalized values across all rows for each population\n",
    "    p2s_dfs.append(pd.DataFrame([p2s] * temp.shape[0], index=temp.index, columns=temp.columns))\n",
    "    twopqs_dfs.append(pd.DataFrame([twopqs] * temp.shape[0], index=temp.index, columns=temp.columns))\n",
    "    q2s_dfs.append(pd.DataFrame([q2s] * temp.shape[0], index=temp.index, columns=temp.columns))\n",
    "\n",
    "# Drop \"pop\" from the original DataFrame\n",
    "complete = complete.drop(\"pop\", axis=1)\n",
    "\n",
    "# Concatenate all population-specific DataFrames\n",
    "true_p2s = pd.concat(p2s_dfs)\n",
    "true_twopqs = pd.concat(twopqs_dfs)\n",
    "true_q2s = pd.concat(q2s_dfs)\n",
    "\n",
    "# Save the resulting DataFrames\n",
    "true_p2s.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/02_true_p2_via_true_pop.pkl\")\n",
    "true_twopqs.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/02_true_twopq_via_true_pop.pkl\")\n",
    "true_q2s.to_pickle(f\"data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/02_true_q2_via_true_pop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "292e58e2-4cbf-4681-959b-1da220a24fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"rm -rf data/G{G}_L{L}_c{c}_k{k}_M{M}_HWE{HWE}/genotype/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90734a76-7b14-488f-bb78-f614c6f7ffe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a096a0-1cbe-470d-b161-5fd2b8b2c76d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
